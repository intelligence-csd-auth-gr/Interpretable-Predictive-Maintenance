{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LioNets: Turbofan Engine Degradation Simulation Dataset with Neural Networks -> Classification Task\n",
    "\n",
    "In this notebook, we present how LioNets can be applied in predictive models using time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "from IPython.display import SVG\n",
    "from IPython.display import display                               \n",
    "from ipywidgets import interactive, BoundedFloatText, FloatSlider, IntSlider, ToggleButtons,  \\\n",
    "    RadioButtons, IntRangeSlider, Dropdown, jslink, jsdlink, interactive_output, HBox, VBox, Label\n",
    "from load_dataset import Load_Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from math import sqrt, exp, log\n",
    "from sklearn.linear_model import Lasso, Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score, balanced_accuracy_score, accuracy_score\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, TimeDistributed, RepeatVector,Flatten, \\\n",
    "    Input, Dropout, LSTM, concatenate, Reshape, Conv1D, GlobalMaxPool1D\n",
    "import keras.backend as K\n",
    "from keras.utils import plot_model\n",
    "from LioNets import LioNet\n",
    "from nbeats_keras.model import NBeatsNet\n",
    "from Interpretable_PCA import iPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we load and clean our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm, feature_names = Load_Dataset.load_data_turbofan(False)\n",
    "\n",
    "fm1_train = fm['FaultMode1']['df_train']\n",
    "fm1_train_target = fm1_train['RUL'].values\n",
    "fm1_test= fm['FaultMode1']['df_test']\n",
    "fm1_test_target = fm1_test['RUL'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dropping some unecessary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_train = fm1_train.drop(columns=['t', 'os_1', 'os_2', 'os_3', 's_01', 's_05', 's_06', 's_10', 's_16', 's_18', 's_19', 's_22', 's_23', 's_24', 's_25', 's_26'])\n",
    "LSTM_test = fm1_test.drop(columns=['t', 'os_1', 'os_2', 'os_3', 's_01', 's_05', 's_06', 's_10', 's_16', 's_18', 's_19', 's_22', 's_23', 's_24', 's_25', 's_26'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We collect the different units, in order to the next steps to create time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_units = set(LSTM_train['u'].values)\n",
    "test_units = set(LSTM_test['u'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are scaling our data per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = ['s_02', 's_03', 's_04', 's_07', 's_08', 's_09', 's_11', 's_12',\n",
    "            's_13', 's_14', 's_15', 's_17', 's_20', 's_21']\n",
    "scalers = {}\n",
    "for column in sensors:\n",
    "    scaler = MinMaxScaler(feature_range=(0.1,1.1))\n",
    "    LSTM_train[column] = scaler.fit_transform(LSTM_train[column].values.reshape(-1,1))\n",
    "    LSTM_test[column] = scaler.transform(LSTM_test[column].values.reshape(-1,1))\n",
    "    scalers[column] = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create time windows with a specific size. In this example, we create time windows of 50 timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_scalers = {}\n",
    "window = 50\n",
    "temp_LSTM_x_train = []\n",
    "LSTM_y_train = []\n",
    "for unit in train_units:\n",
    "    temp_unit = LSTM_train[LSTM_train['u']==unit].drop(columns=['u','RUL']).values\n",
    "    temp_unit_RUL = LSTM_train[LSTM_train['u']==unit]['RUL'].values\n",
    "    \n",
    "    for i in range(len(temp_unit) - window + 1):#elekse edw an len temp_unit - window > 0\n",
    "        temp_instance = []\n",
    "        for j in range(window):\n",
    "            temp_instance.append(temp_unit[i+j])\n",
    "        temp_LSTM_x_train.append(np.array(temp_instance))\n",
    "        LSTM_y_train.append(temp_unit_RUL[i+window-1])\n",
    "LSTM_y_train = np.array(LSTM_y_train)\n",
    "LSTM_x_train = np.array(temp_LSTM_x_train)\n",
    "\n",
    "temp_LSTM_x_test = []\n",
    "LSTM_y_test = []\n",
    "for unit in test_units:\n",
    "    temp_unit = LSTM_test[LSTM_test['u']==unit].drop(columns=['u','RUL']).values\n",
    "    temp_unit_RUL = LSTM_test[LSTM_test['u']==unit]['RUL'].values\n",
    "        \n",
    "    for i in range(len(temp_unit) - window + 1):#elekse edw an len temp_unit - window > 0\n",
    "        temp_instance = []\n",
    "        for j in range(window):\n",
    "            temp_instance.append(temp_unit[i+j])\n",
    "        temp_LSTM_x_test.append(np.array(temp_instance))\n",
    "        LSTM_y_test.append(temp_unit_RUL[i+window-1])\n",
    "LSTM_y_test = np.array(LSTM_y_test)\n",
    "LSTM_x_test = np.array(temp_LSTM_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how many train, test instances we have. These are changing regarding the time window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15731, 50, 14), (8255, 50, 14), (15731,), (8255,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_x_train.shape, LSTM_x_test.shape, LSTM_y_train.shape, LSTM_y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to transform our RUL to binary classes. 0 Would mean that no maintenance is needed, because the prediction had a high RUL value. 1 would mean that the RUL is low and you may need maintenance on your component! You can try different time frames as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_frame = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_LSTM_y_train = np.array([1 if i <= time_frame else 0 for i in LSTM_y_train])\n",
    "temp_LSTM_y_test = np.array([1 if i <= time_frame else 0 for i in LSTM_y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We need a rmse loss function too! for the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can build our predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "feature_names = fm1_train.columns\n",
    "encoder_input = Input(shape=(LSTM_x_train[0].shape))\n",
    "\n",
    "encoder_x = LSTM(units=80, return_sequences=True, activation='tanh')(encoder_input)\n",
    "encoder_x = Dropout(0.5)(encoder_x)\n",
    "encoder_x = LSTM(units=40, return_sequences=False, activation='tanh')(encoder_x)\n",
    "\n",
    "encoder_y = Conv1D(filters=40,kernel_size=3,activation='tanh')(encoder_input)\n",
    "encoder_y = GlobalMaxPool1D()(encoder_y)\n",
    "\n",
    "encoded = concatenate([encoder_x,encoder_y])\n",
    "encoded = Dropout(0.5)(encoded)\n",
    "encoded = Dense(80, activation='tanh')(encoded)#Relu and selu\n",
    "encoded = Dropout(0.5)(encoded)\n",
    "encoded = Dense(40, activation='tanh')(encoded)#Relu and selu\n",
    "predictions = Dense(1, activation='sigmoid')(encoded)#Relu and selu\n",
    "predictor = Model(encoder_input,predictions)\n",
    "\n",
    "predictor.compile(optimizer=\"adam\",loss=['binary_crossentropy'],metrics=['accuracy'])\n",
    "#print(predictor.summary())\n",
    "\n",
    "checkpoint_name = 'TEDS_Predictor_Classification.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 2, save_best_only = True, mode ='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictor.fit(LSTM_x_train, temp_LSTM_y_train, epochs=250, batch_size=512, shuffle=True, validation_split=0.33, verbose=2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load our weights, and we measure the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wights_file = 'TEDS_Predictor_Classification.hdf5' # choose the best checkpoint few features\n",
    "predictor.load_weights(wights_file) # load it\n",
    "predictor.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pred = predictor.predict(LSTM_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9758438751509758 0.9756563803680429 0.9542879398101445 0.9758438751509758\n",
      "Test: 0.9855844942459115 0.9845923721401666 0.8467556329064839 0.9855844942459115\n"
     ]
    }
   ],
   "source": [
    "temp_pred = predictor.predict(LSTM_x_train)\n",
    "predictions = [0 if i[0] <=0.5 else 1 for i in temp_pred]\n",
    "print('Train:',f1_score(temp_LSTM_y_train,predictions, average='micro'),f1_score(temp_LSTM_y_train,predictions, average='weighted'),balanced_accuracy_score(temp_LSTM_y_train,predictions),accuracy_score(temp_LSTM_y_train,predictions))\n",
    "\n",
    "temp_pred = predictor.predict(LSTM_x_test)\n",
    "predictions = [0 if i[0] <=0.5 else 1 for i in temp_pred]\n",
    "print('Test:',f1_score(temp_LSTM_y_test,predictions, average='micro'),f1_score(temp_LSTM_y_test,predictions, average='weighted'),balanced_accuracy_score(temp_LSTM_y_test,predictions),accuracy_score(temp_LSTM_y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we have to extract the encoder from our predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(input=predictor.input, output=[predictor.layers[-2].output])\n",
    "encoder.trainable = False\n",
    "encoder.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])\n",
    "#encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to extract for all instances, their encoded representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_LSTM_x_train = encoder.predict(LSTM_x_train)\n",
    "encoded_LSTM_x_test = encoder.predict(LSTM_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And by that, we build the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(encoded_LSTM_x_train[0].shape))\n",
    "decoded = Dense(120, activation='tanh')(encoded_input)\n",
    "decoded = Dropout(0.5)(decoded)\n",
    "\n",
    "decoded_y = RepeatVector(54)(decoded)\n",
    "decoded_y = Conv1D(filters=50,kernel_size=5,activation='tanh')(decoded_y)\n",
    "\n",
    "decoded_x = RepeatVector(50)(decoded)\n",
    "decoded_x = LSTM(units=80, return_sequences=True, activation='tanh')(decoded_x)\n",
    "decoded_x = Dropout(0.5)(decoded_x)\n",
    "decoded_x = LSTM(units=50, return_sequences=True, activation='tanh')(decoded_x)\n",
    "\n",
    "decoded = concatenate([decoded_x,decoded_y])\n",
    "decoded = Dense(50, activation='sigmoid')(decoded)\n",
    "decoded = Dropout(0.5)(decoded)\n",
    "decoded = Dense(14, activation='sigmoid')(decoded)\n",
    "\n",
    "decoder = Model(encoded_input,decoded)\n",
    "\n",
    "decoder.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])\n",
    "#print(decoder.summary())\n",
    "\n",
    "checkpoint_name = 'TEDS_Decoder_Classification.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 2, save_best_only = True, mode ='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder.fit(encoded_LSTM_x_train, LSTM_x_train, epochs=250, batch_size=512, shuffle=True, validation_split=0.33, verbose=2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wights_file = 'TEDS_Decoder_Classification.hdf5' # choose the best checkpoint few features\n",
    "decoder.load_weights(wights_file) # load it\n",
    "decoder.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15731/15731 [==============================] - 7s 454us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06820674527842154, 0.052121663511208616, 0.004656450242404678]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.evaluate(encoded_LSTM_x_train,LSTM_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8255/8255 [==============================] - 3s 421us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06830550037067201, 0.052297253303820984, 0.0046694804948705535]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.evaluate(encoded_LSTM_x_test,LSTM_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 50\n",
    "forecast_timesteps = 5\n",
    "\n",
    "temp_fc_x_train = []\n",
    "temp_fc_y_train = []\n",
    "for unit in train_units:\n",
    "    temp_unit = LSTM_train[LSTM_train['u']==unit].drop(columns=['u','RUL']).values\n",
    "   \n",
    "    for i in range(len(temp_unit) - window - forecast_timesteps + 1):#elekse edw an len temp_unit - window > 0\n",
    "        temp_instance_x = []\n",
    "        temp_instance_y = []\n",
    "        for j in range(window):\n",
    "            temp_instance_x.append(temp_unit[i+j])\n",
    "        for z in range(forecast_timesteps):\n",
    "            temp_instance_y.append(temp_unit[i+j+z+1])            \n",
    "        temp_fc_x_train.append(np.array(temp_instance_x))\n",
    "        temp_fc_y_train.append(np.array(temp_instance_y))       \n",
    "fc_x_train = np.array(temp_fc_x_train)\n",
    "fc_y_train = np.array(temp_fc_y_train)\n",
    "\n",
    "temp_fc_x_test = []\n",
    "temp_fc_y_test = []\n",
    "for unit in test_units:\n",
    "    temp_unit = LSTM_test[LSTM_test['u']==unit].drop(columns=['u','RUL']).values\n",
    "        \n",
    "    for i in range(len(temp_unit) - window - forecast_timesteps + 1):#elekse edw an len temp_unit - window > 0\n",
    "        temp_instance_x = []\n",
    "        temp_instance_y = []\n",
    "        for j in range(window):\n",
    "            temp_instance_x.append(temp_unit[i+j])\n",
    "        for z in range(forecast_timesteps):\n",
    "            temp_instance_y.append(temp_unit[i+j+z+1])            \n",
    "        temp_fc_x_test.append(np.array(temp_instance_x))\n",
    "        temp_fc_y_test.append(np.array(temp_instance_y))       \n",
    "fc_x_test = np.array(temp_fc_x_test)\n",
    "fc_y_test = np.array(temp_fc_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15231, 50, 14), (7794, 50, 14), (15231, 5, 14), (7794, 5, 14))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_x_train.shape, fc_x_test.shape, fc_y_train.shape, fc_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 50, 14)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 50, 120)      64800       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 50, 120)      0           lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 50, 50)       34200       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 5, 50)        32250       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 5, 50)        115050      lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 5, 100)       0           conv1d_4[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 5, 100)       0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 5, 40)        22560       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 5, 40)        0           lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 5, 14)        3080        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 271,940\n",
      "Trainable params: 271,940\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "forecast_input = Input(shape=(LSTM_x_train[0].shape))\n",
    "\n",
    "forecast_x = LSTM(units=120, return_sequences=True, activation='tanh')(forecast_input)\n",
    "forecast_x = Dropout(0.7)(forecast_x)\n",
    "forecast_x = LSTM(units=50, return_sequences=True, activation='tanh')(forecast_x)\n",
    "forecast_x = Conv1D(filters=50,kernel_size=46,activation='tanh')(forecast_x)\n",
    "\n",
    "forecast_y = Conv1D(filters=50,kernel_size=46,activation='tanh')(forecast_input)\n",
    "\n",
    "forecast = concatenate([forecast_y,forecast_x])\n",
    "forecast = Dropout(0.7)(forecast)\n",
    "forecast = LSTM(40, return_sequences=True, activation='relu')(forecast)#Relu and selu\n",
    "forecast = Dropout(0.7)(forecast)\n",
    "predictions = LSTM(14, return_sequences=True, activation='linear')(forecast)#Relu and selu\n",
    "forecaster = Model(forecast_input,predictions)\n",
    "forecaster.summary()\n",
    "forecaster.compile(optimizer=\"adam\", loss=[root_mean_squared_error],metrics=['mae','mse'])\n",
    "\n",
    "checkpoint_name = 'TEDS_Forecaster_Classification_Matrix.hdf5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 2, save_best_only = True, mode ='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#forecaster.fit(fc_x_train, fc_y_train, epochs=250, batch_size=512, shuffle=True, validation_split=0.3, verbose=2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = 'TEDS_Forecaster_Classification_Matrix.hdf5' # choose the best checkpoint few features\n",
    "forecaster.load_weights(weights_file) # load it\n",
    "forecaster.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = forecaster.predict(fc_x_train)\n",
    "# print('Train:',mean_absolute_error(fc_y_train.reshape(-1,70),predictions.reshape(-1,70)),mean_squared_error(fc_y_train.reshape(-1,70),predictions.reshape(-1,70)),sqrt(mean_squared_error(fc_y_train.reshape(-1,70),predictions.reshape(-1,70))))\n",
    "# print(r2_score(fc_y_train.reshape(-1,70),predictions.reshape(-1,70)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = forecaster.predict(fc_x_test)\n",
    "# print('Test:',mean_absolute_error(fc_y_test.reshape(-1,70),predictions.reshape(-1,70)),mean_squared_error(fc_y_test.reshape(-1,70),predictions.reshape(-1,70)),sqrt(mean_squared_error(fc_y_test.reshape(-1,70),predictions.reshape(-1,70))))\n",
    "# print(r2_score(fc_y_test.reshape(-1,70),predictions.reshape(-1,70)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## N-Beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_variable (InputLayer)     (None, 50, 14)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "0/0/generic/d1 (Dense)          (None, 64)           3264        lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 subtract[0][0]                   \n",
      "                                                                 subtract_1[0][0]                 \n",
      "                                                                 subtract_2[0][0]                 \n",
      "                                                                 subtract_3[0][0]                 \n",
      "                                                                 subtract_4[0][0]                 \n",
      "                                                                 subtract_5[0][0]                 \n",
      "                                                                 subtract_6[0][0]                 \n",
      "                                                                 subtract_7[0][0]                 \n",
      "                                                                 subtract_8[0][0]                 \n",
      "                                                                 subtract_9[0][0]                 \n",
      "                                                                 subtract_10[0][0]                \n",
      "                                                                 subtract_11[0][0]                \n",
      "                                                                 subtract_12[0][0]                \n",
      "                                                                 subtract_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "0/0/generic/d2 (Dense)          (None, 64)           4160        0/0/generic/d1[0][0]             \n",
      "                                                                 0/0/generic/d1[1][0]             \n",
      "                                                                 0/0/generic/d1[2][0]             \n",
      "                                                                 0/0/generic/d1[3][0]             \n",
      "                                                                 0/0/generic/d1[4][0]             \n",
      "                                                                 0/0/generic/d1[5][0]             \n",
      "                                                                 0/0/generic/d1[6][0]             \n",
      "                                                                 0/0/generic/d1[7][0]             \n",
      "                                                                 0/0/generic/d1[8][0]             \n",
      "                                                                 0/0/generic/d1[9][0]             \n",
      "                                                                 0/0/generic/d1[10][0]            \n",
      "                                                                 0/0/generic/d1[11][0]            \n",
      "                                                                 0/0/generic/d1[12][0]            \n",
      "                                                                 0/0/generic/d1[13][0]            \n",
      "                                                                 0/0/generic/d1[14][0]            \n",
      "                                                                 0/0/generic/d1[15][0]            \n",
      "                                                                 0/0/generic/d1[16][0]            \n",
      "                                                                 0/0/generic/d1[17][0]            \n",
      "                                                                 0/0/generic/d1[18][0]            \n",
      "                                                                 0/0/generic/d1[19][0]            \n",
      "                                                                 0/0/generic/d1[20][0]            \n",
      "                                                                 0/0/generic/d1[21][0]            \n",
      "                                                                 0/0/generic/d1[22][0]            \n",
      "                                                                 0/0/generic/d1[23][0]            \n",
      "                                                                 0/0/generic/d1[24][0]            \n",
      "                                                                 0/0/generic/d1[25][0]            \n",
      "                                                                 0/0/generic/d1[26][0]            \n",
      "                                                                 0/0/generic/d1[27][0]            \n",
      "__________________________________________________________________________________________________\n",
      "0/0/generic/d3 (Dense)          (None, 64)           4160        0/0/generic/d2[0][0]             \n",
      "                                                                 0/0/generic/d2[1][0]             \n",
      "                                                                 0/0/generic/d2[2][0]             \n",
      "                                                                 0/0/generic/d2[3][0]             \n",
      "                                                                 0/0/generic/d2[4][0]             \n",
      "                                                                 0/0/generic/d2[5][0]             \n",
      "                                                                 0/0/generic/d2[6][0]             \n",
      "                                                                 0/0/generic/d2[7][0]             \n",
      "                                                                 0/0/generic/d2[8][0]             \n",
      "                                                                 0/0/generic/d2[9][0]             \n",
      "                                                                 0/0/generic/d2[10][0]            \n",
      "                                                                 0/0/generic/d2[11][0]            \n",
      "                                                                 0/0/generic/d2[12][0]            \n",
      "                                                                 0/0/generic/d2[13][0]            \n",
      "                                                                 0/0/generic/d2[14][0]            \n",
      "                                                                 0/0/generic/d2[15][0]            \n",
      "                                                                 0/0/generic/d2[16][0]            \n",
      "                                                                 0/0/generic/d2[17][0]            \n",
      "                                                                 0/0/generic/d2[18][0]            \n",
      "                                                                 0/0/generic/d2[19][0]            \n",
      "                                                                 0/0/generic/d2[20][0]            \n",
      "                                                                 0/0/generic/d2[21][0]            \n",
      "                                                                 0/0/generic/d2[22][0]            \n",
      "                                                                 0/0/generic/d2[23][0]            \n",
      "                                                                 0/0/generic/d2[24][0]            \n",
      "                                                                 0/0/generic/d2[25][0]            \n",
      "                                                                 0/0/generic/d2[26][0]            \n",
      "                                                                 0/0/generic/d2[27][0]            \n",
      "__________________________________________________________________________________________________\n",
      "0/0/generic/d4 (Dense)          (None, 64)           4160        0/0/generic/d3[0][0]             \n",
      "                                                                 0/0/generic/d3[1][0]             \n",
      "                                                                 0/0/generic/d3[2][0]             \n",
      "                                                                 0/0/generic/d3[3][0]             \n",
      "                                                                 0/0/generic/d3[4][0]             \n",
      "                                                                 0/0/generic/d3[5][0]             \n",
      "                                                                 0/0/generic/d3[6][0]             \n",
      "                                                                 0/0/generic/d3[7][0]             \n",
      "                                                                 0/0/generic/d3[8][0]             \n",
      "                                                                 0/0/generic/d3[9][0]             \n",
      "                                                                 0/0/generic/d3[10][0]            \n",
      "                                                                 0/0/generic/d3[11][0]            \n",
      "                                                                 0/0/generic/d3[12][0]            \n",
      "                                                                 0/0/generic/d3[13][0]            \n",
      "                                                                 0/0/generic/d3[14][0]            \n",
      "                                                                 0/0/generic/d3[15][0]            \n",
      "                                                                 0/0/generic/d3[16][0]            \n",
      "                                                                 0/0/generic/d3[17][0]            \n",
      "                                                                 0/0/generic/d3[18][0]            \n",
      "                                                                 0/0/generic/d3[19][0]            \n",
      "                                                                 0/0/generic/d3[20][0]            \n",
      "                                                                 0/0/generic/d3[21][0]            \n",
      "                                                                 0/0/generic/d3[22][0]            \n",
      "                                                                 0/0/generic/d3[23][0]            \n",
      "                                                                 0/0/generic/d3[24][0]            \n",
      "                                                                 0/0/generic/d3[25][0]            \n",
      "                                                                 0/0/generic/d3[26][0]            \n",
      "                                                                 0/0/generic/d3[27][0]            \n",
      "__________________________________________________________________________________________________\n",
      "0/0/generic/theta_b (Dense)     (None, 4)            256         0/0/generic/d4[0][0]             \n",
      "                                                                 0/0/generic/d4[1][0]             \n",
      "                                                                 0/0/generic/d4[2][0]             \n",
      "                                                                 0/0/generic/d4[3][0]             \n",
      "                                                                 0/0/generic/d4[4][0]             \n",
      "                                                                 0/0/generic/d4[5][0]             \n",
      "                                                                 0/0/generic/d4[6][0]             \n",
      "                                                                 0/0/generic/d4[7][0]             \n",
      "                                                                 0/0/generic/d4[8][0]             \n",
      "                                                                 0/0/generic/d4[9][0]             \n",
      "                                                                 0/0/generic/d4[10][0]            \n",
      "                                                                 0/0/generic/d4[11][0]            \n",
      "                                                                 0/0/generic/d4[12][0]            \n",
      "                                                                 0/0/generic/d4[13][0]            \n",
      "                                                                 0/0/generic/d4[14][0]            \n",
      "                                                                 0/0/generic/d4[15][0]            \n",
      "                                                                 0/0/generic/d4[16][0]            \n",
      "                                                                 0/0/generic/d4[17][0]            \n",
      "                                                                 0/0/generic/d4[18][0]            \n",
      "                                                                 0/0/generic/d4[19][0]            \n",
      "                                                                 0/0/generic/d4[20][0]            \n",
      "                                                                 0/0/generic/d4[21][0]            \n",
      "                                                                 0/0/generic/d4[22][0]            \n",
      "                                                                 0/0/generic/d4[23][0]            \n",
      "                                                                 0/0/generic/d4[24][0]            \n",
      "                                                                 0/0/generic/d4[25][0]            \n",
      "                                                                 0/0/generic/d4[26][0]            \n",
      "                                                                 0/0/generic/d4[27][0]            \n",
      "__________________________________________________________________________________________________\n",
      "0/0/generic/backcast (Dense)    (None, 50)           250         0/0/generic/theta_b[0][0]        \n",
      "                                                                 0/0/generic/theta_b[1][0]        \n",
      "                                                                 0/0/generic/theta_b[2][0]        \n",
      "                                                                 0/0/generic/theta_b[3][0]        \n",
      "                                                                 0/0/generic/theta_b[4][0]        \n",
      "                                                                 0/0/generic/theta_b[5][0]        \n",
      "                                                                 0/0/generic/theta_b[6][0]        \n",
      "                                                                 0/0/generic/theta_b[7][0]        \n",
      "                                                                 0/0/generic/theta_b[8][0]        \n",
      "                                                                 0/0/generic/theta_b[9][0]        \n",
      "                                                                 0/0/generic/theta_b[10][0]       \n",
      "                                                                 0/0/generic/theta_b[11][0]       \n",
      "                                                                 0/0/generic/theta_b[12][0]       \n",
      "                                                                 0/0/generic/theta_b[13][0]       \n",
      "                                                                 0/0/generic/theta_b[14][0]       \n",
      "                                                                 0/0/generic/theta_b[15][0]       \n",
      "                                                                 0/0/generic/theta_b[16][0]       \n",
      "                                                                 0/0/generic/theta_b[17][0]       \n",
      "                                                                 0/0/generic/theta_b[18][0]       \n",
      "                                                                 0/0/generic/theta_b[19][0]       \n",
      "                                                                 0/0/generic/theta_b[20][0]       \n",
      "                                                                 0/0/generic/theta_b[21][0]       \n",
      "                                                                 0/0/generic/theta_b[22][0]       \n",
      "                                                                 0/0/generic/theta_b[23][0]       \n",
      "                                                                 0/0/generic/theta_b[24][0]       \n",
      "                                                                 0/0/generic/theta_b[25][0]       \n",
      "                                                                 0/0/generic/theta_b[26][0]       \n",
      "                                                                 0/0/generic/theta_b[27][0]       \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 50)           0           lambda[0][0]                     \n",
      "                                                                 0/0/generic/backcast[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_14 (Subtract)          (None, 50)           0           subtract[0][0]                   \n",
      "                                                                 0/0/generic/backcast[14][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 50)           0           lambda_1[0][0]                   \n",
      "                                                                 0/0/generic/backcast[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "1/0/generic/d1 (Dense)          (None, 64)           3264        subtract_14[0][0]                \n",
      "                                                                 subtract_15[0][0]                \n",
      "                                                                 subtract_16[0][0]                \n",
      "                                                                 subtract_17[0][0]                \n",
      "                                                                 subtract_18[0][0]                \n",
      "                                                                 subtract_19[0][0]                \n",
      "                                                                 subtract_20[0][0]                \n",
      "                                                                 subtract_21[0][0]                \n",
      "                                                                 subtract_22[0][0]                \n",
      "                                                                 subtract_23[0][0]                \n",
      "                                                                 subtract_24[0][0]                \n",
      "                                                                 subtract_25[0][0]                \n",
      "                                                                 subtract_26[0][0]                \n",
      "                                                                 subtract_27[0][0]                \n",
      "                                                                 subtract_28[0][0]                \n",
      "                                                                 subtract_29[0][0]                \n",
      "                                                                 subtract_30[0][0]                \n",
      "                                                                 subtract_31[0][0]                \n",
      "                                                                 subtract_32[0][0]                \n",
      "                                                                 subtract_33[0][0]                \n",
      "                                                                 subtract_34[0][0]                \n",
      "                                                                 subtract_35[0][0]                \n",
      "                                                                 subtract_36[0][0]                \n",
      "                                                                 subtract_37[0][0]                \n",
      "                                                                 subtract_38[0][0]                \n",
      "                                                                 subtract_39[0][0]                \n",
      "                                                                 subtract_40[0][0]                \n",
      "                                                                 subtract_41[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "1/0/generic/d2 (Dense)          (None, 64)           4160        1/0/generic/d1[0][0]             \n",
      "                                                                 1/0/generic/d1[1][0]             \n",
      "                                                                 1/0/generic/d1[2][0]             \n",
      "                                                                 1/0/generic/d1[3][0]             \n",
      "                                                                 1/0/generic/d1[4][0]             \n",
      "                                                                 1/0/generic/d1[5][0]             \n",
      "                                                                 1/0/generic/d1[6][0]             \n",
      "                                                                 1/0/generic/d1[7][0]             \n",
      "                                                                 1/0/generic/d1[8][0]             \n",
      "                                                                 1/0/generic/d1[9][0]             \n",
      "                                                                 1/0/generic/d1[10][0]            \n",
      "                                                                 1/0/generic/d1[11][0]            \n",
      "                                                                 1/0/generic/d1[12][0]            \n",
      "                                                                 1/0/generic/d1[13][0]            \n",
      "                                                                 1/0/generic/d1[14][0]            \n",
      "                                                                 1/0/generic/d1[15][0]            \n",
      "                                                                 1/0/generic/d1[16][0]            \n",
      "                                                                 1/0/generic/d1[17][0]            \n",
      "                                                                 1/0/generic/d1[18][0]            \n",
      "                                                                 1/0/generic/d1[19][0]            \n",
      "                                                                 1/0/generic/d1[20][0]            \n",
      "                                                                 1/0/generic/d1[21][0]            \n",
      "                                                                 1/0/generic/d1[22][0]            \n",
      "                                                                 1/0/generic/d1[23][0]            \n",
      "                                                                 1/0/generic/d1[24][0]            \n",
      "                                                                 1/0/generic/d1[25][0]            \n",
      "                                                                 1/0/generic/d1[26][0]            \n",
      "                                                                 1/0/generic/d1[27][0]            \n",
      "__________________________________________________________________________________________________\n",
      "1/0/generic/d3 (Dense)          (None, 64)           4160        1/0/generic/d2[0][0]             \n",
      "                                                                 1/0/generic/d2[1][0]             \n",
      "                                                                 1/0/generic/d2[2][0]             \n",
      "                                                                 1/0/generic/d2[3][0]             \n",
      "                                                                 1/0/generic/d2[4][0]             \n",
      "                                                                 1/0/generic/d2[5][0]             \n",
      "                                                                 1/0/generic/d2[6][0]             \n",
      "                                                                 1/0/generic/d2[7][0]             \n",
      "                                                                 1/0/generic/d2[8][0]             \n",
      "                                                                 1/0/generic/d2[9][0]             \n",
      "                                                                 1/0/generic/d2[10][0]            \n",
      "                                                                 1/0/generic/d2[11][0]            \n",
      "                                                                 1/0/generic/d2[12][0]            \n",
      "                                                                 1/0/generic/d2[13][0]            \n",
      "                                                                 1/0/generic/d2[14][0]            \n",
      "                                                                 1/0/generic/d2[15][0]            \n",
      "                                                                 1/0/generic/d2[16][0]            \n",
      "                                                                 1/0/generic/d2[17][0]            \n",
      "                                                                 1/0/generic/d2[18][0]            \n",
      "                                                                 1/0/generic/d2[19][0]            \n",
      "                                                                 1/0/generic/d2[20][0]            \n",
      "                                                                 1/0/generic/d2[21][0]            \n",
      "                                                                 1/0/generic/d2[22][0]            \n",
      "                                                                 1/0/generic/d2[23][0]            \n",
      "                                                                 1/0/generic/d2[24][0]            \n",
      "                                                                 1/0/generic/d2[25][0]            \n",
      "                                                                 1/0/generic/d2[26][0]            \n",
      "                                                                 1/0/generic/d2[27][0]            \n",
      "__________________________________________________________________________________________________\n",
      "1/0/generic/d4 (Dense)          (None, 64)           4160        1/0/generic/d3[0][0]             \n",
      "                                                                 1/0/generic/d3[1][0]             \n",
      "                                                                 1/0/generic/d3[2][0]             \n",
      "                                                                 1/0/generic/d3[3][0]             \n",
      "                                                                 1/0/generic/d3[4][0]             \n",
      "                                                                 1/0/generic/d3[5][0]             \n",
      "                                                                 1/0/generic/d3[6][0]             \n",
      "                                                                 1/0/generic/d3[7][0]             \n",
      "                                                                 1/0/generic/d3[8][0]             \n",
      "                                                                 1/0/generic/d3[9][0]             \n",
      "                                                                 1/0/generic/d3[10][0]            \n",
      "                                                                 1/0/generic/d3[11][0]            \n",
      "                                                                 1/0/generic/d3[12][0]            \n",
      "                                                                 1/0/generic/d3[13][0]            \n",
      "                                                                 1/0/generic/d3[14][0]            \n",
      "                                                                 1/0/generic/d3[15][0]            \n",
      "                                                                 1/0/generic/d3[16][0]            \n",
      "                                                                 1/0/generic/d3[17][0]            \n",
      "                                                                 1/0/generic/d3[18][0]            \n",
      "                                                                 1/0/generic/d3[19][0]            \n",
      "                                                                 1/0/generic/d3[20][0]            \n",
      "                                                                 1/0/generic/d3[21][0]            \n",
      "                                                                 1/0/generic/d3[22][0]            \n",
      "                                                                 1/0/generic/d3[23][0]            \n",
      "                                                                 1/0/generic/d3[24][0]            \n",
      "                                                                 1/0/generic/d3[25][0]            \n",
      "                                                                 1/0/generic/d3[26][0]            \n",
      "                                                                 1/0/generic/d3[27][0]            \n",
      "__________________________________________________________________________________________________\n",
      "1/0/generic/theta_b (Dense)     (None, 4)            256         1/0/generic/d4[0][0]             \n",
      "                                                                 1/0/generic/d4[1][0]             \n",
      "                                                                 1/0/generic/d4[2][0]             \n",
      "                                                                 1/0/generic/d4[3][0]             \n",
      "                                                                 1/0/generic/d4[4][0]             \n",
      "                                                                 1/0/generic/d4[5][0]             \n",
      "                                                                 1/0/generic/d4[6][0]             \n",
      "                                                                 1/0/generic/d4[7][0]             \n",
      "                                                                 1/0/generic/d4[8][0]             \n",
      "                                                                 1/0/generic/d4[9][0]             \n",
      "                                                                 1/0/generic/d4[10][0]            \n",
      "                                                                 1/0/generic/d4[11][0]            \n",
      "                                                                 1/0/generic/d4[12][0]            \n",
      "                                                                 1/0/generic/d4[13][0]            \n",
      "__________________________________________________________________________________________________\n",
      "1/0/generic/backcast (Dense)    (None, 50)           250         1/0/generic/theta_b[0][0]        \n",
      "                                                                 1/0/generic/theta_b[1][0]        \n",
      "                                                                 1/0/generic/theta_b[2][0]        \n",
      "                                                                 1/0/generic/theta_b[3][0]        \n",
      "                                                                 1/0/generic/theta_b[4][0]        \n",
      "                                                                 1/0/generic/theta_b[5][0]        \n",
      "                                                                 1/0/generic/theta_b[6][0]        \n",
      "                                                                 1/0/generic/theta_b[7][0]        \n",
      "                                                                 1/0/generic/theta_b[8][0]        \n",
      "                                                                 1/0/generic/theta_b[9][0]        \n",
      "                                                                 1/0/generic/theta_b[10][0]       \n",
      "                                                                 1/0/generic/theta_b[11][0]       \n",
      "                                                                 1/0/generic/theta_b[12][0]       \n",
      "                                                                 1/0/generic/theta_b[13][0]       \n",
      "__________________________________________________________________________________________________\n",
      "subtract_28 (Subtract)          (None, 50)           0           subtract_14[0][0]                \n",
      "                                                                 1/0/generic/backcast[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "subtract_15 (Subtract)          (None, 50)           0           subtract_1[0][0]                 \n",
      "                                                                 0/0/generic/backcast[15][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 50)           0           lambda_2[0][0]                   \n",
      "                                                                 0/0/generic/backcast[2][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_29 (Subtract)          (None, 50)           0           subtract_15[0][0]                \n",
      "                                                                 1/0/generic/backcast[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "subtract_16 (Subtract)          (None, 50)           0           subtract_2[0][0]                 \n",
      "                                                                 0/0/generic/backcast[16][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 50)           0           lambda_3[0][0]                   \n",
      "                                                                 0/0/generic/backcast[3][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_30 (Subtract)          (None, 50)           0           subtract_16[0][0]                \n",
      "                                                                 1/0/generic/backcast[2][0]       \n",
      "__________________________________________________________________________________________________\n",
      "subtract_17 (Subtract)          (None, 50)           0           subtract_3[0][0]                 \n",
      "                                                                 0/0/generic/backcast[17][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_4 (Subtract)           (None, 50)           0           lambda_4[0][0]                   \n",
      "                                                                 0/0/generic/backcast[4][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_31 (Subtract)          (None, 50)           0           subtract_17[0][0]                \n",
      "                                                                 1/0/generic/backcast[3][0]       \n",
      "__________________________________________________________________________________________________\n",
      "subtract_18 (Subtract)          (None, 50)           0           subtract_4[0][0]                 \n",
      "                                                                 0/0/generic/backcast[18][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_5 (Subtract)           (None, 50)           0           lambda_5[0][0]                   \n",
      "                                                                 0/0/generic/backcast[5][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_32 (Subtract)          (None, 50)           0           subtract_18[0][0]                \n",
      "                                                                 1/0/generic/backcast[4][0]       \n",
      "__________________________________________________________________________________________________\n",
      "subtract_19 (Subtract)          (None, 50)           0           subtract_5[0][0]                 \n",
      "                                                                 0/0/generic/backcast[19][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_6 (Subtract)           (None, 50)           0           lambda_6[0][0]                   \n",
      "                                                                 0/0/generic/backcast[6][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_33 (Subtract)          (None, 50)           0           subtract_19[0][0]                \n",
      "                                                                 1/0/generic/backcast[5][0]       \n",
      "__________________________________________________________________________________________________\n",
      "subtract_20 (Subtract)          (None, 50)           0           subtract_6[0][0]                 \n",
      "                                                                 0/0/generic/backcast[20][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_7 (Subtract)           (None, 50)           0           lambda_7[0][0]                   \n",
      "                                                                 0/0/generic/backcast[7][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_34 (Subtract)          (None, 50)           0           subtract_20[0][0]                \n",
      "                                                                 1/0/generic/backcast[6][0]       \n",
      "__________________________________________________________________________________________________\n",
      "subtract_21 (Subtract)          (None, 50)           0           subtract_7[0][0]                 \n",
      "                                                                 0/0/generic/backcast[21][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_8 (Subtract)           (None, 50)           0           lambda_8[0][0]                   \n",
      "                                                                 0/0/generic/backcast[8][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_35 (Subtract)          (None, 50)           0           subtract_21[0][0]                \n",
      "                                                                 1/0/generic/backcast[7][0]       \n",
      "__________________________________________________________________________________________________\n",
      "subtract_22 (Subtract)          (None, 50)           0           subtract_8[0][0]                 \n",
      "                                                                 0/0/generic/backcast[22][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_9 (Subtract)           (None, 50)           0           lambda_9[0][0]                   \n",
      "                                                                 0/0/generic/backcast[9][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_36 (Subtract)          (None, 50)           0           subtract_22[0][0]                \n",
      "                                                                 1/0/generic/backcast[8][0]       \n",
      "__________________________________________________________________________________________________\n",
      "subtract_23 (Subtract)          (None, 50)           0           subtract_9[0][0]                 \n",
      "                                                                 0/0/generic/backcast[23][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_10 (Subtract)          (None, 50)           0           lambda_10[0][0]                  \n",
      "                                                                 0/0/generic/backcast[10][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_37 (Subtract)          (None, 50)           0           subtract_23[0][0]                \n",
      "                                                                 1/0/generic/backcast[9][0]       \n",
      "__________________________________________________________________________________________________\n",
      "subtract_24 (Subtract)          (None, 50)           0           subtract_10[0][0]                \n",
      "                                                                 0/0/generic/backcast[24][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_11 (Subtract)          (None, 50)           0           lambda_11[0][0]                  \n",
      "                                                                 0/0/generic/backcast[11][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_38 (Subtract)          (None, 50)           0           subtract_24[0][0]                \n",
      "                                                                 1/0/generic/backcast[10][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_25 (Subtract)          (None, 50)           0           subtract_11[0][0]                \n",
      "                                                                 0/0/generic/backcast[25][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_12 (Subtract)          (None, 50)           0           lambda_12[0][0]                  \n",
      "                                                                 0/0/generic/backcast[12][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 50)           0           input_variable[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_39 (Subtract)          (None, 50)           0           subtract_25[0][0]                \n",
      "                                                                 1/0/generic/backcast[11][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_26 (Subtract)          (None, 50)           0           subtract_12[0][0]                \n",
      "                                                                 0/0/generic/backcast[26][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_13 (Subtract)          (None, 50)           0           lambda_13[0][0]                  \n",
      "                                                                 0/0/generic/backcast[13][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_40 (Subtract)          (None, 50)           0           subtract_26[0][0]                \n",
      "                                                                 1/0/generic/backcast[12][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_27 (Subtract)          (None, 50)           0           subtract_13[0][0]                \n",
      "                                                                 0/0/generic/backcast[27][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_41 (Subtract)          (None, 50)           0           subtract_27[0][0]                \n",
      "                                                                 1/0/generic/backcast[13][0]      \n",
      "__________________________________________________________________________________________________\n",
      "0/0/generic/theta_f (Dense)     (None, 4)            256         0/0/generic/d4[0][0]             \n",
      "                                                                 0/0/generic/d4[1][0]             \n",
      "                                                                 0/0/generic/d4[2][0]             \n",
      "                                                                 0/0/generic/d4[3][0]             \n",
      "                                                                 0/0/generic/d4[4][0]             \n",
      "                                                                 0/0/generic/d4[5][0]             \n",
      "                                                                 0/0/generic/d4[6][0]             \n",
      "                                                                 0/0/generic/d4[7][0]             \n",
      "                                                                 0/0/generic/d4[8][0]             \n",
      "                                                                 0/0/generic/d4[9][0]             \n",
      "                                                                 0/0/generic/d4[10][0]            \n",
      "                                                                 0/0/generic/d4[11][0]            \n",
      "                                                                 0/0/generic/d4[12][0]            \n",
      "                                                                 0/0/generic/d4[13][0]            \n",
      "                                                                 0/0/generic/d4[14][0]            \n",
      "                                                                 0/0/generic/d4[15][0]            \n",
      "                                                                 0/0/generic/d4[16][0]            \n",
      "                                                                 0/0/generic/d4[17][0]            \n",
      "                                                                 0/0/generic/d4[18][0]            \n",
      "                                                                 0/0/generic/d4[19][0]            \n",
      "                                                                 0/0/generic/d4[20][0]            \n",
      "                                                                 0/0/generic/d4[21][0]            \n",
      "                                                                 0/0/generic/d4[22][0]            \n",
      "                                                                 0/0/generic/d4[23][0]            \n",
      "                                                                 0/0/generic/d4[24][0]            \n",
      "                                                                 0/0/generic/d4[25][0]            \n",
      "                                                                 0/0/generic/d4[26][0]            \n",
      "                                                                 0/0/generic/d4[27][0]            \n",
      "__________________________________________________________________________________________________\n",
      "0/0/generic/forecast (Dense)    (None, 5)            25          0/0/generic/theta_f[0][0]        \n",
      "                                                                 0/0/generic/theta_f[1][0]        \n",
      "                                                                 0/0/generic/theta_f[2][0]        \n",
      "                                                                 0/0/generic/theta_f[3][0]        \n",
      "                                                                 0/0/generic/theta_f[4][0]        \n",
      "                                                                 0/0/generic/theta_f[5][0]        \n",
      "                                                                 0/0/generic/theta_f[6][0]        \n",
      "                                                                 0/0/generic/theta_f[7][0]        \n",
      "                                                                 0/0/generic/theta_f[8][0]        \n",
      "                                                                 0/0/generic/theta_f[9][0]        \n",
      "                                                                 0/0/generic/theta_f[10][0]       \n",
      "                                                                 0/0/generic/theta_f[11][0]       \n",
      "                                                                 0/0/generic/theta_f[12][0]       \n",
      "                                                                 0/0/generic/theta_f[13][0]       \n",
      "                                                                 0/0/generic/theta_f[14][0]       \n",
      "                                                                 0/0/generic/theta_f[15][0]       \n",
      "                                                                 0/0/generic/theta_f[16][0]       \n",
      "                                                                 0/0/generic/theta_f[17][0]       \n",
      "                                                                 0/0/generic/theta_f[18][0]       \n",
      "                                                                 0/0/generic/theta_f[19][0]       \n",
      "                                                                 0/0/generic/theta_f[20][0]       \n",
      "                                                                 0/0/generic/theta_f[21][0]       \n",
      "                                                                 0/0/generic/theta_f[22][0]       \n",
      "                                                                 0/0/generic/theta_f[23][0]       \n",
      "                                                                 0/0/generic/theta_f[24][0]       \n",
      "                                                                 0/0/generic/theta_f[25][0]       \n",
      "                                                                 0/0/generic/theta_f[26][0]       \n",
      "                                                                 0/0/generic/theta_f[27][0]       \n",
      "__________________________________________________________________________________________________\n",
      "1/0/generic/theta_f (Dense)     (None, 4)            256         1/0/generic/d4[0][0]             \n",
      "                                                                 1/0/generic/d4[1][0]             \n",
      "                                                                 1/0/generic/d4[2][0]             \n",
      "                                                                 1/0/generic/d4[3][0]             \n",
      "                                                                 1/0/generic/d4[4][0]             \n",
      "                                                                 1/0/generic/d4[5][0]             \n",
      "                                                                 1/0/generic/d4[6][0]             \n",
      "                                                                 1/0/generic/d4[7][0]             \n",
      "                                                                 1/0/generic/d4[8][0]             \n",
      "                                                                 1/0/generic/d4[9][0]             \n",
      "                                                                 1/0/generic/d4[10][0]            \n",
      "                                                                 1/0/generic/d4[11][0]            \n",
      "                                                                 1/0/generic/d4[12][0]            \n",
      "                                                                 1/0/generic/d4[13][0]            \n",
      "                                                                 1/0/generic/d4[14][0]            \n",
      "                                                                 1/0/generic/d4[15][0]            \n",
      "                                                                 1/0/generic/d4[16][0]            \n",
      "                                                                 1/0/generic/d4[17][0]            \n",
      "                                                                 1/0/generic/d4[18][0]            \n",
      "                                                                 1/0/generic/d4[19][0]            \n",
      "                                                                 1/0/generic/d4[20][0]            \n",
      "                                                                 1/0/generic/d4[21][0]            \n",
      "                                                                 1/0/generic/d4[22][0]            \n",
      "                                                                 1/0/generic/d4[23][0]            \n",
      "                                                                 1/0/generic/d4[24][0]            \n",
      "                                                                 1/0/generic/d4[25][0]            \n",
      "                                                                 1/0/generic/d4[26][0]            \n",
      "                                                                 1/0/generic/d4[27][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 5)            0           0/0/generic/forecast[0][0]       \n",
      "                                                                 0/0/generic/forecast[14][0]      \n",
      "__________________________________________________________________________________________________\n",
      "1/0/generic/forecast (Dense)    (None, 5)            25          1/0/generic/theta_f[0][0]        \n",
      "                                                                 1/0/generic/theta_f[1][0]        \n",
      "                                                                 1/0/generic/theta_f[2][0]        \n",
      "                                                                 1/0/generic/theta_f[3][0]        \n",
      "                                                                 1/0/generic/theta_f[4][0]        \n",
      "                                                                 1/0/generic/theta_f[5][0]        \n",
      "                                                                 1/0/generic/theta_f[6][0]        \n",
      "                                                                 1/0/generic/theta_f[7][0]        \n",
      "                                                                 1/0/generic/theta_f[8][0]        \n",
      "                                                                 1/0/generic/theta_f[9][0]        \n",
      "                                                                 1/0/generic/theta_f[10][0]       \n",
      "                                                                 1/0/generic/theta_f[11][0]       \n",
      "                                                                 1/0/generic/theta_f[12][0]       \n",
      "                                                                 1/0/generic/theta_f[13][0]       \n",
      "                                                                 1/0/generic/theta_f[14][0]       \n",
      "                                                                 1/0/generic/theta_f[15][0]       \n",
      "                                                                 1/0/generic/theta_f[16][0]       \n",
      "                                                                 1/0/generic/theta_f[17][0]       \n",
      "                                                                 1/0/generic/theta_f[18][0]       \n",
      "                                                                 1/0/generic/theta_f[19][0]       \n",
      "                                                                 1/0/generic/theta_f[20][0]       \n",
      "                                                                 1/0/generic/theta_f[21][0]       \n",
      "                                                                 1/0/generic/theta_f[22][0]       \n",
      "                                                                 1/0/generic/theta_f[23][0]       \n",
      "                                                                 1/0/generic/theta_f[24][0]       \n",
      "                                                                 1/0/generic/theta_f[25][0]       \n",
      "                                                                 1/0/generic/theta_f[26][0]       \n",
      "                                                                 1/0/generic/theta_f[27][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 5)            0           0/0/generic/forecast[1][0]       \n",
      "                                                                 0/0/generic/forecast[15][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 5)            0           0/0/generic/forecast[2][0]       \n",
      "                                                                 0/0/generic/forecast[16][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 5)            0           0/0/generic/forecast[3][0]       \n",
      "                                                                 0/0/generic/forecast[17][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 5)            0           0/0/generic/forecast[4][0]       \n",
      "                                                                 0/0/generic/forecast[18][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 5)            0           0/0/generic/forecast[5][0]       \n",
      "                                                                 0/0/generic/forecast[19][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 5)            0           0/0/generic/forecast[6][0]       \n",
      "                                                                 0/0/generic/forecast[20][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 5)            0           0/0/generic/forecast[7][0]       \n",
      "                                                                 0/0/generic/forecast[21][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 5)            0           0/0/generic/forecast[8][0]       \n",
      "                                                                 0/0/generic/forecast[22][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 5)            0           0/0/generic/forecast[9][0]       \n",
      "                                                                 0/0/generic/forecast[23][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 5)            0           0/0/generic/forecast[10][0]      \n",
      "                                                                 0/0/generic/forecast[24][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 5)            0           0/0/generic/forecast[11][0]      \n",
      "                                                                 0/0/generic/forecast[25][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 5)            0           0/0/generic/forecast[12][0]      \n",
      "                                                                 0/0/generic/forecast[26][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 5)            0           0/0/generic/forecast[13][0]      \n",
      "                                                                 0/0/generic/forecast[27][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 5)            0           add[0][0]                        \n",
      "                                                                 1/0/generic/forecast[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 5)            0           add_1[0][0]                      \n",
      "                                                                 1/0/generic/forecast[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 5)            0           add_2[0][0]                      \n",
      "                                                                 1/0/generic/forecast[2][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 5)            0           add_3[0][0]                      \n",
      "                                                                 1/0/generic/forecast[3][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 5)            0           add_4[0][0]                      \n",
      "                                                                 1/0/generic/forecast[4][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 5)            0           add_5[0][0]                      \n",
      "                                                                 1/0/generic/forecast[5][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 5)            0           add_6[0][0]                      \n",
      "                                                                 1/0/generic/forecast[6][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 5)            0           add_7[0][0]                      \n",
      "                                                                 1/0/generic/forecast[7][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 5)            0           add_8[0][0]                      \n",
      "                                                                 1/0/generic/forecast[8][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 5)            0           add_9[0][0]                      \n",
      "                                                                 1/0/generic/forecast[9][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 5)            0           add_10[0][0]                     \n",
      "                                                                 1/0/generic/forecast[10][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 5)            0           add_11[0][0]                     \n",
      "                                                                 1/0/generic/forecast[11][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 5)            0           add_12[0][0]                     \n",
      "                                                                 1/0/generic/forecast[12][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 5)            0           add_13[0][0]                     \n",
      "                                                                 1/0/generic/forecast[13][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 5)            0           add_14[0][0]                     \n",
      "                                                                 1/0/generic/forecast[14][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 5)            0           add_15[0][0]                     \n",
      "                                                                 1/0/generic/forecast[15][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 5)            0           add_16[0][0]                     \n",
      "                                                                 1/0/generic/forecast[16][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 5)            0           add_17[0][0]                     \n",
      "                                                                 1/0/generic/forecast[17][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 5)            0           add_18[0][0]                     \n",
      "                                                                 1/0/generic/forecast[18][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 5)            0           add_19[0][0]                     \n",
      "                                                                 1/0/generic/forecast[19][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 5)            0           add_20[0][0]                     \n",
      "                                                                 1/0/generic/forecast[20][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 5)            0           add_21[0][0]                     \n",
      "                                                                 1/0/generic/forecast[21][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 5)            0           add_22[0][0]                     \n",
      "                                                                 1/0/generic/forecast[22][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 5)            0           add_23[0][0]                     \n",
      "                                                                 1/0/generic/forecast[23][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 5)            0           add_24[0][0]                     \n",
      "                                                                 1/0/generic/forecast[24][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 5)            0           add_25[0][0]                     \n",
      "                                                                 1/0/generic/forecast[25][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 5)            0           add_26[0][0]                     \n",
      "                                                                 1/0/generic/forecast[26][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 5)            0           add_27[0][0]                     \n",
      "                                                                 1/0/generic/forecast[27][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 5, 1)         0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 5, 1)         0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 5, 1)         0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 5, 1)         0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 5, 1)         0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 5, 1)         0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 5, 1)         0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 5, 1)         0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 5, 1)         0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 5, 1)         0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 5, 1)         0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 5, 1)         0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 5, 1)         0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 5, 1)         0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 14)        0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "                                                                 reshape_12[0][0]                 \n",
      "                                                                 reshape_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 33,062\n",
      "Trainable params: 33,062\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Definition of the model.\n",
    "nbeats = NBeatsNet(input_dim = 14, backcast_length=50, forecast_length=5,\n",
    "                  stack_types=(NBeatsNet.GENERIC_BLOCK, NBeatsNet.GENERIC_BLOCK), \n",
    "                  nb_blocks_per_stack=2,\n",
    "                  thetas_dim=(4, 4), \n",
    "                  share_weights_in_stack=True, \n",
    "                  hidden_layer_units=64)\n",
    "\n",
    "# Definition of the objective function and the optimizer.\n",
    "nbeats.compile_model(loss='mae', learning_rate=1e-6)\n",
    " \n",
    "# Train the model.\n",
    "#nbeats.fit(fc_x_train, fc_y_train, verbose=1, validation_split=0.3, epochs=100, batch_size=128)\n",
    "\n",
    "# Save the model for later.\n",
    "#nbeats.save('n_beats_model.h5')\n",
    "\n",
    "# # Load the model.\n",
    "nbeats = NBeatsNet.load('n_beats_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = nbeats.predict(fc_x_train)\n",
    "# print('Train:',mean_absolute_error(fc_y_train.reshape(-1,70),predictions.reshape(-1,70)),mean_squared_error(fc_y_train.reshape(-1,70),predictions.reshape(-1,70)),sqrt(mean_squared_error(fc_y_train.reshape(-1,70),predictions.reshape(-1,70))))\n",
    "# print(r2_score(fc_y_train.reshape(-1,70),predictions.reshape(-1,70)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = nbeats.predict(fc_x_test)\n",
    "# print('Test:',mean_absolute_error(fc_y_test.reshape(-1,70),predictions.reshape(-1,70)),mean_squared_error(fc_y_test.reshape(-1,70),predictions.reshape(-1,70)),sqrt(mean_squared_error(fc_y_test.reshape(-1,70),predictions.reshape(-1,70))))\n",
    "# print(r2_score(fc_y_test.reshape(-1,70),predictions.reshape(-1,70)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbf99f2e310>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sens = 10\n",
    "j = 123\n",
    "temp_instance = fc_x_train[j].copy()[np.newaxis]\n",
    "nbts = nbeats.predict(temp_instance)\n",
    "pred = forecaster.predict(temp_instance)\n",
    "ln = temp_instance.shape[1]\n",
    "plt.plot(np.arange(ln), temp_instance.squeeze()[:,sens], color='black')\n",
    "plt.plot(np.arange(ln-1,ln+5), np.append(temp_instance.squeeze()[-1:,sens],fc_y_test[j][:,sens]), color='g') # Ground Truth\n",
    "plt.plot(np.arange(ln-1,ln+5), np.append(temp_instance.squeeze()[-1:,sens],pred.squeeze()[:,sens]), color='b') # Neural Forecast \n",
    "plt.plot(np.arange(ln-1,ln+5), np.append(temp_instance.squeeze()[-1:,sens],nbts.squeeze()[:,sens]), color='r') # NBeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## XYZ7 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 50\n",
    "forecast_steps = 5\n",
    "\n",
    "rul_train, xyz7_x_train, xyz7_y_train, rul_temp = [],[],[],[]\n",
    "for unit in train_units:\n",
    "    temp_unit = LSTM_train[LSTM_train['u']==unit].drop(columns=['u','RUL']).values   \n",
    "    for i in range(len(temp_unit) - window + 1): # elekse edw an len temp_unit - window > 0\n",
    "        temp_instance = np.array(temp_unit[i:i+window])\n",
    "        rul_temp.append(temp_instance)\n",
    "        xyz7_x_train.append(temp_instance[:-forecast_steps])\n",
    "        xyz7_y_train.append(temp_instance[-forecast_steps:])\n",
    "\n",
    "rul_train = predictor.predict(np.array(rul_temp))\n",
    "xyz7_x_train = np.array(xyz7_x_train)\n",
    "xyz7_y_train = np.array(xyz7_y_train)\n",
    "\n",
    "rul_test, xyz7_x_test, xyz7_y_test, rul_temp = [],[],[],[]\n",
    "for unit in test_units:\n",
    "    temp_unit = LSTM_test[LSTM_test['u']==unit].drop(columns=['u','RUL']).values   \n",
    "    for i in range(len(temp_unit) - window + 1): # elekse edw an len temp_unit - window > 0\n",
    "        temp_instance = np.array(temp_unit[i:i+window])\n",
    "        rul_temp.append(temp_instance)\n",
    "        xyz7_x_test.append(temp_instance[:-forecast_steps])\n",
    "        xyz7_y_test.append(temp_instance[-forecast_steps:])\n",
    "\n",
    "rul_test = predictor.predict(np.array(rul_temp))\n",
    "xyz7_x_test = np.array(xyz7_x_test)\n",
    "xyz7_y_test = np.array(xyz7_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15731, 1), (15731, 45, 14), (15731, 5, 14))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rul_train.shape , xyz7_x_train.shape , xyz7_y_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forecast_input = Input(shape=(xyz7_x_train[0].shape))\n",
    "rul_input = Input(shape = (rul_train[0].shape))\n",
    "rul = RepeatVector(5)(rul_input)\n",
    "\n",
    "forecast_x = LSTM(units=120, return_sequences=True, activation='tanh')(forecast_input)\n",
    "forecast_x = Dropout(0.7)(forecast_x)\n",
    "forecast_x = LSTM(units=50, return_sequences=True, activation='tanh')(forecast_x)\n",
    "forecast_x = Conv1D(filters=50,kernel_size=41,activation='tanh')(forecast_x)\n",
    "forecast_x = concatenate([forecast_x, rul])\n",
    "\n",
    "\n",
    "forecast_y = Conv1D(filters=50,kernel_size=41,activation='tanh')(forecast_input)\n",
    "forecast_y = concatenate([forecast_y, rul])\n",
    "\n",
    "\n",
    "forecast = concatenate([forecast_y, forecast_x, rul])\n",
    "forecast = Dropout(0.7)(forecast)\n",
    "forecast = LSTM(40, return_sequences=True, activation='relu')(forecast)#Relu and selu\n",
    "forecast = concatenate([forecast, rul])\n",
    "forecast = Dropout(0.7)(forecast)\n",
    "predictions = LSTM(14, return_sequences=True, activation='linear')(forecast)#Relu and selu\n",
    "\n",
    "xyz7_model = Model([forecast_input, rul_input],predictions)\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "xyz7_model.compile(optimizer=opt, loss=[root_mean_squared_error],metrics=['mae','mse'])\n",
    "\n",
    "checkpoint_name = 'TEDS_XYZ7_Classification.hdf5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 2, save_best_only = True, mode ='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11011 samples, validate on 4720 samples\n",
      "Epoch 1/250\n",
      " - 13s - loss: 0.4664 - mean_absolute_error: 0.4093 - mean_squared_error: 0.2193 - val_loss: 0.3689 - val_mean_absolute_error: 0.3084 - val_mean_squared_error: 0.1361\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36893, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 2/250\n",
      " - 8s - loss: 0.3759 - mean_absolute_error: 0.3154 - mean_squared_error: 0.1418 - val_loss: 0.2719 - val_mean_absolute_error: 0.2134 - val_mean_squared_error: 0.0739\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.36893 to 0.27186, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 3/250\n",
      " - 8s - loss: 0.3047 - mean_absolute_error: 0.2447 - mean_squared_error: 0.0932 - val_loss: 0.1932 - val_mean_absolute_error: 0.1447 - val_mean_squared_error: 0.0374\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.27186 to 0.19321, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 4/250\n",
      " - 8s - loss: 0.2490 - mean_absolute_error: 0.1921 - mean_squared_error: 0.0622 - val_loss: 0.1567 - val_mean_absolute_error: 0.1172 - val_mean_squared_error: 0.0246\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.19321 to 0.15668, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 5/250\n",
      " - 8s - loss: 0.2111 - mean_absolute_error: 0.1588 - mean_squared_error: 0.0446 - val_loss: 0.1230 - val_mean_absolute_error: 0.0921 - val_mean_squared_error: 0.0151\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15668 to 0.12295, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 6/250\n",
      " - 8s - loss: 0.1864 - mean_absolute_error: 0.1384 - mean_squared_error: 0.0348 - val_loss: 0.1011 - val_mean_absolute_error: 0.0785 - val_mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12295 to 0.10114, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 7/250\n",
      " - 9s - loss: 0.1694 - mean_absolute_error: 0.1250 - mean_squared_error: 0.0287 - val_loss: 0.0968 - val_mean_absolute_error: 0.0750 - val_mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10114 to 0.09678, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 8/250\n",
      " - 8s - loss: 0.1549 - mean_absolute_error: 0.1141 - mean_squared_error: 0.0240 - val_loss: 0.0909 - val_mean_absolute_error: 0.0710 - val_mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.09678 to 0.09089, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 9/250\n",
      " - 8s - loss: 0.1436 - mean_absolute_error: 0.1057 - mean_squared_error: 0.0206 - val_loss: 0.0873 - val_mean_absolute_error: 0.0683 - val_mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09089 to 0.08730, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 10/250\n",
      " - 8s - loss: 0.1351 - mean_absolute_error: 0.0995 - mean_squared_error: 0.0183 - val_loss: 0.0862 - val_mean_absolute_error: 0.0673 - val_mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.08730 to 0.08622, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 11/250\n",
      " - 9s - loss: 0.1284 - mean_absolute_error: 0.0948 - mean_squared_error: 0.0165 - val_loss: 0.0841 - val_mean_absolute_error: 0.0657 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.08622 to 0.08407, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 12/250\n",
      " - 9s - loss: 0.1219 - mean_absolute_error: 0.0901 - mean_squared_error: 0.0149 - val_loss: 0.0824 - val_mean_absolute_error: 0.0646 - val_mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.08407 to 0.08236, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 13/250\n",
      " - 9s - loss: 0.1180 - mean_absolute_error: 0.0873 - mean_squared_error: 0.0139 - val_loss: 0.0837 - val_mean_absolute_error: 0.0653 - val_mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.08236\n",
      "Epoch 14/250\n",
      " - 8s - loss: 0.1139 - mean_absolute_error: 0.0846 - mean_squared_error: 0.0130 - val_loss: 0.0829 - val_mean_absolute_error: 0.0650 - val_mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.08236\n",
      "Epoch 15/250\n",
      " - 8s - loss: 0.1100 - mean_absolute_error: 0.0820 - mean_squared_error: 0.0121 - val_loss: 0.0794 - val_mean_absolute_error: 0.0620 - val_mean_squared_error: 0.0063\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08236 to 0.07945, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 16/250\n",
      " - 8s - loss: 0.1062 - mean_absolute_error: 0.0793 - mean_squared_error: 0.0113 - val_loss: 0.0787 - val_mean_absolute_error: 0.0613 - val_mean_squared_error: 0.0062\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.07945 to 0.07865, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 17/250\n",
      " - 9s - loss: 0.1039 - mean_absolute_error: 0.0776 - mean_squared_error: 0.0108 - val_loss: 0.0778 - val_mean_absolute_error: 0.0603 - val_mean_squared_error: 0.0061\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.07865 to 0.07782, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 18/250\n",
      " - 8s - loss: 0.1015 - mean_absolute_error: 0.0761 - mean_squared_error: 0.0103 - val_loss: 0.0761 - val_mean_absolute_error: 0.0589 - val_mean_squared_error: 0.0058\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.07782 to 0.07607, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 19/250\n",
      " - 8s - loss: 0.0996 - mean_absolute_error: 0.0745 - mean_squared_error: 0.0099 - val_loss: 0.0772 - val_mean_absolute_error: 0.0597 - val_mean_squared_error: 0.0060\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.07607\n",
      "Epoch 20/250\n",
      " - 9s - loss: 0.0972 - mean_absolute_error: 0.0730 - mean_squared_error: 0.0094 - val_loss: 0.0763 - val_mean_absolute_error: 0.0591 - val_mean_squared_error: 0.0058\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07607\n",
      "Epoch 21/250\n",
      " - 8s - loss: 0.0958 - mean_absolute_error: 0.0721 - mean_squared_error: 0.0092 - val_loss: 0.0750 - val_mean_absolute_error: 0.0580 - val_mean_squared_error: 0.0056\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.07607 to 0.07503, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 22/250\n",
      " - 8s - loss: 0.0948 - mean_absolute_error: 0.0714 - mean_squared_error: 0.0090 - val_loss: 0.0755 - val_mean_absolute_error: 0.0581 - val_mean_squared_error: 0.0057\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.07503\n",
      "Epoch 23/250\n",
      " - 8s - loss: 0.0941 - mean_absolute_error: 0.0709 - mean_squared_error: 0.0089 - val_loss: 0.0753 - val_mean_absolute_error: 0.0581 - val_mean_squared_error: 0.0057\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.07503\n",
      "Epoch 24/250\n",
      " - 9s - loss: 0.0929 - mean_absolute_error: 0.0701 - mean_squared_error: 0.0086 - val_loss: 0.0752 - val_mean_absolute_error: 0.0577 - val_mean_squared_error: 0.0057\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.07503\n",
      "Epoch 25/250\n",
      " - 8s - loss: 0.0917 - mean_absolute_error: 0.0693 - mean_squared_error: 0.0084 - val_loss: 0.0754 - val_mean_absolute_error: 0.0578 - val_mean_squared_error: 0.0057\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.07503\n",
      "Epoch 26/250\n",
      " - 8s - loss: 0.0909 - mean_absolute_error: 0.0687 - mean_squared_error: 0.0083 - val_loss: 0.0749 - val_mean_absolute_error: 0.0574 - val_mean_squared_error: 0.0056\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.07503 to 0.07488, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 27/250\n",
      " - 9s - loss: 0.0900 - mean_absolute_error: 0.0680 - mean_squared_error: 0.0081 - val_loss: 0.0739 - val_mean_absolute_error: 0.0568 - val_mean_squared_error: 0.0055\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.07488 to 0.07388, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 28/250\n",
      " - 8s - loss: 0.0893 - mean_absolute_error: 0.0676 - mean_squared_error: 0.0080 - val_loss: 0.0742 - val_mean_absolute_error: 0.0574 - val_mean_squared_error: 0.0055\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.07388\n",
      "Epoch 29/250\n",
      " - 8s - loss: 0.0885 - mean_absolute_error: 0.0671 - mean_squared_error: 0.0078 - val_loss: 0.0738 - val_mean_absolute_error: 0.0567 - val_mean_squared_error: 0.0055\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.07388 to 0.07381, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 30/250\n",
      " - 8s - loss: 0.0878 - mean_absolute_error: 0.0665 - mean_squared_error: 0.0077 - val_loss: 0.0732 - val_mean_absolute_error: 0.0561 - val_mean_squared_error: 0.0054\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.07381 to 0.07316, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 31/250\n",
      " - 8s - loss: 0.0874 - mean_absolute_error: 0.0662 - mean_squared_error: 0.0076 - val_loss: 0.0728 - val_mean_absolute_error: 0.0559 - val_mean_squared_error: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: val_loss improved from 0.07316 to 0.07279, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 32/250\n",
      " - 8s - loss: 0.0869 - mean_absolute_error: 0.0658 - mean_squared_error: 0.0075 - val_loss: 0.0737 - val_mean_absolute_error: 0.0565 - val_mean_squared_error: 0.0054\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.07279\n",
      "Epoch 33/250\n",
      " - 8s - loss: 0.0868 - mean_absolute_error: 0.0658 - mean_squared_error: 0.0075 - val_loss: 0.0738 - val_mean_absolute_error: 0.0566 - val_mean_squared_error: 0.0055\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.07279\n",
      "Epoch 34/250\n",
      " - 9s - loss: 0.0861 - mean_absolute_error: 0.0652 - mean_squared_error: 0.0074 - val_loss: 0.0736 - val_mean_absolute_error: 0.0566 - val_mean_squared_error: 0.0054\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.07279\n",
      "Epoch 35/250\n",
      " - 8s - loss: 0.0853 - mean_absolute_error: 0.0648 - mean_squared_error: 0.0073 - val_loss: 0.0735 - val_mean_absolute_error: 0.0565 - val_mean_squared_error: 0.0054\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.07279\n",
      "Epoch 36/250\n",
      " - 8s - loss: 0.0851 - mean_absolute_error: 0.0645 - mean_squared_error: 0.0072 - val_loss: 0.0727 - val_mean_absolute_error: 0.0557 - val_mean_squared_error: 0.0053\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.07279 to 0.07265, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 37/250\n",
      " - 8s - loss: 0.0844 - mean_absolute_error: 0.0641 - mean_squared_error: 0.0071 - val_loss: 0.0720 - val_mean_absolute_error: 0.0551 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.07265 to 0.07198, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 38/250\n",
      " - 8s - loss: 0.0846 - mean_absolute_error: 0.0642 - mean_squared_error: 0.0072 - val_loss: 0.0728 - val_mean_absolute_error: 0.0557 - val_mean_squared_error: 0.0053\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.07198\n",
      "Epoch 39/250\n",
      " - 8s - loss: 0.0839 - mean_absolute_error: 0.0638 - mean_squared_error: 0.0070 - val_loss: 0.0720 - val_mean_absolute_error: 0.0551 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.07198\n",
      "Epoch 40/250\n",
      " - 9s - loss: 0.0838 - mean_absolute_error: 0.0636 - mean_squared_error: 0.0070 - val_loss: 0.0721 - val_mean_absolute_error: 0.0552 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.07198\n",
      "Epoch 41/250\n",
      " - 8s - loss: 0.0838 - mean_absolute_error: 0.0635 - mean_squared_error: 0.0070 - val_loss: 0.0734 - val_mean_absolute_error: 0.0567 - val_mean_squared_error: 0.0054\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.07198\n",
      "Epoch 42/250\n",
      " - 8s - loss: 0.0839 - mean_absolute_error: 0.0636 - mean_squared_error: 0.0070 - val_loss: 0.0728 - val_mean_absolute_error: 0.0558 - val_mean_squared_error: 0.0053\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.07198\n",
      "Epoch 43/250\n",
      " - 8s - loss: 0.0835 - mean_absolute_error: 0.0634 - mean_squared_error: 0.0070 - val_loss: 0.0721 - val_mean_absolute_error: 0.0553 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07198\n",
      "Epoch 44/250\n",
      " - 8s - loss: 0.0834 - mean_absolute_error: 0.0633 - mean_squared_error: 0.0070 - val_loss: 0.0724 - val_mean_absolute_error: 0.0555 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07198\n",
      "Epoch 45/250\n",
      " - 8s - loss: 0.0832 - mean_absolute_error: 0.0632 - mean_squared_error: 0.0069 - val_loss: 0.0721 - val_mean_absolute_error: 0.0552 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.07198\n",
      "Epoch 46/250\n",
      " - 8s - loss: 0.0826 - mean_absolute_error: 0.0627 - mean_squared_error: 0.0068 - val_loss: 0.0719 - val_mean_absolute_error: 0.0551 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.07198 to 0.07186, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 47/250\n",
      " - 8s - loss: 0.0822 - mean_absolute_error: 0.0625 - mean_squared_error: 0.0068 - val_loss: 0.0720 - val_mean_absolute_error: 0.0551 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07186\n",
      "Epoch 48/250\n",
      " - 9s - loss: 0.0820 - mean_absolute_error: 0.0625 - mean_squared_error: 0.0067 - val_loss: 0.0717 - val_mean_absolute_error: 0.0549 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.07186 to 0.07169, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 49/250\n",
      " - 9s - loss: 0.0817 - mean_absolute_error: 0.0622 - mean_squared_error: 0.0067 - val_loss: 0.0720 - val_mean_absolute_error: 0.0551 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07169\n",
      "Epoch 50/250\n",
      " - 8s - loss: 0.0816 - mean_absolute_error: 0.0621 - mean_squared_error: 0.0067 - val_loss: 0.0716 - val_mean_absolute_error: 0.0548 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.07169 to 0.07164, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 51/250\n",
      " - 8s - loss: 0.0816 - mean_absolute_error: 0.0621 - mean_squared_error: 0.0067 - val_loss: 0.0717 - val_mean_absolute_error: 0.0548 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.07164\n",
      "Epoch 52/250\n",
      " - 8s - loss: 0.0813 - mean_absolute_error: 0.0619 - mean_squared_error: 0.0066 - val_loss: 0.0718 - val_mean_absolute_error: 0.0552 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.07164\n",
      "Epoch 53/250\n",
      " - 8s - loss: 0.0811 - mean_absolute_error: 0.0617 - mean_squared_error: 0.0066 - val_loss: 0.0722 - val_mean_absolute_error: 0.0553 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.07164\n",
      "Epoch 54/250\n",
      " - 8s - loss: 0.0813 - mean_absolute_error: 0.0619 - mean_squared_error: 0.0066 - val_loss: 0.0718 - val_mean_absolute_error: 0.0549 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.07164\n",
      "Epoch 55/250\n",
      " - 8s - loss: 0.0808 - mean_absolute_error: 0.0616 - mean_squared_error: 0.0065 - val_loss: 0.0717 - val_mean_absolute_error: 0.0548 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.07164\n",
      "Epoch 56/250\n",
      " - 8s - loss: 0.0808 - mean_absolute_error: 0.0615 - mean_squared_error: 0.0065 - val_loss: 0.0715 - val_mean_absolute_error: 0.0548 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.07164 to 0.07146, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 57/250\n",
      " - 8s - loss: 0.0808 - mean_absolute_error: 0.0615 - mean_squared_error: 0.0065 - val_loss: 0.0715 - val_mean_absolute_error: 0.0548 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.07146\n",
      "Epoch 58/250\n",
      " - 8s - loss: 0.0804 - mean_absolute_error: 0.0613 - mean_squared_error: 0.0065 - val_loss: 0.0714 - val_mean_absolute_error: 0.0548 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.07146 to 0.07137, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 59/250\n",
      " - 9s - loss: 0.0803 - mean_absolute_error: 0.0612 - mean_squared_error: 0.0065 - val_loss: 0.0719 - val_mean_absolute_error: 0.0550 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.07137\n",
      "Epoch 60/250\n",
      " - 9s - loss: 0.0804 - mean_absolute_error: 0.0612 - mean_squared_error: 0.0065 - val_loss: 0.0720 - val_mean_absolute_error: 0.0554 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.07137\n",
      "Epoch 61/250\n",
      " - 9s - loss: 0.0802 - mean_absolute_error: 0.0611 - mean_squared_error: 0.0064 - val_loss: 0.0718 - val_mean_absolute_error: 0.0550 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.07137\n",
      "Epoch 62/250\n",
      " - 9s - loss: 0.0803 - mean_absolute_error: 0.0612 - mean_squared_error: 0.0064 - val_loss: 0.0724 - val_mean_absolute_error: 0.0556 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.07137\n",
      "Epoch 63/250\n",
      " - 9s - loss: 0.0800 - mean_absolute_error: 0.0609 - mean_squared_error: 0.0064 - val_loss: 0.0714 - val_mean_absolute_error: 0.0548 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.07137\n",
      "Epoch 64/250\n",
      " - 9s - loss: 0.0798 - mean_absolute_error: 0.0607 - mean_squared_error: 0.0064 - val_loss: 0.0713 - val_mean_absolute_error: 0.0545 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07137 to 0.07128, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 65/250\n",
      " - 9s - loss: 0.0799 - mean_absolute_error: 0.0609 - mean_squared_error: 0.0064 - val_loss: 0.0720 - val_mean_absolute_error: 0.0550 - val_mean_squared_error: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00065: val_loss did not improve from 0.07128\n",
      "Epoch 66/250\n",
      " - 8s - loss: 0.0801 - mean_absolute_error: 0.0610 - mean_squared_error: 0.0064 - val_loss: 0.0713 - val_mean_absolute_error: 0.0545 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.07128\n",
      "Epoch 67/250\n",
      " - 9s - loss: 0.0796 - mean_absolute_error: 0.0607 - mean_squared_error: 0.0063 - val_loss: 0.0712 - val_mean_absolute_error: 0.0546 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.07128 to 0.07119, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 68/250\n",
      " - 8s - loss: 0.0798 - mean_absolute_error: 0.0608 - mean_squared_error: 0.0064 - val_loss: 0.0716 - val_mean_absolute_error: 0.0547 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.07119\n",
      "Epoch 69/250\n",
      " - 8s - loss: 0.0797 - mean_absolute_error: 0.0606 - mean_squared_error: 0.0063 - val_loss: 0.0717 - val_mean_absolute_error: 0.0548 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.07119\n",
      "Epoch 70/250\n",
      " - 9s - loss: 0.0797 - mean_absolute_error: 0.0607 - mean_squared_error: 0.0064 - val_loss: 0.0717 - val_mean_absolute_error: 0.0549 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.07119\n",
      "Epoch 71/250\n",
      " - 8s - loss: 0.0793 - mean_absolute_error: 0.0604 - mean_squared_error: 0.0063 - val_loss: 0.0712 - val_mean_absolute_error: 0.0544 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.07119\n",
      "Epoch 72/250\n",
      " - 9s - loss: 0.0796 - mean_absolute_error: 0.0606 - mean_squared_error: 0.0063 - val_loss: 0.0718 - val_mean_absolute_error: 0.0549 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.07119\n",
      "Epoch 73/250\n",
      " - 8s - loss: 0.0794 - mean_absolute_error: 0.0604 - mean_squared_error: 0.0063 - val_loss: 0.0715 - val_mean_absolute_error: 0.0548 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.07119\n",
      "Epoch 74/250\n",
      " - 8s - loss: 0.0793 - mean_absolute_error: 0.0604 - mean_squared_error: 0.0063 - val_loss: 0.0713 - val_mean_absolute_error: 0.0545 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.07119\n",
      "Epoch 75/250\n",
      " - 8s - loss: 0.0789 - mean_absolute_error: 0.0602 - mean_squared_error: 0.0062 - val_loss: 0.0710 - val_mean_absolute_error: 0.0543 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.07119 to 0.07099, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 76/250\n",
      " - 8s - loss: 0.0789 - mean_absolute_error: 0.0601 - mean_squared_error: 0.0062 - val_loss: 0.0710 - val_mean_absolute_error: 0.0542 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.07099\n",
      "Epoch 77/250\n",
      " - 8s - loss: 0.0789 - mean_absolute_error: 0.0601 - mean_squared_error: 0.0062 - val_loss: 0.0711 - val_mean_absolute_error: 0.0543 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07099\n",
      "Epoch 78/250\n",
      " - 8s - loss: 0.0788 - mean_absolute_error: 0.0600 - mean_squared_error: 0.0062 - val_loss: 0.0714 - val_mean_absolute_error: 0.0545 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.07099\n",
      "Epoch 79/250\n",
      " - 9s - loss: 0.0790 - mean_absolute_error: 0.0601 - mean_squared_error: 0.0062 - val_loss: 0.0709 - val_mean_absolute_error: 0.0543 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.07099 to 0.07095, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 80/250\n",
      " - 10s - loss: 0.0789 - mean_absolute_error: 0.0601 - mean_squared_error: 0.0062 - val_loss: 0.0712 - val_mean_absolute_error: 0.0545 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.07095\n",
      "Epoch 81/250\n",
      " - 8s - loss: 0.0791 - mean_absolute_error: 0.0603 - mean_squared_error: 0.0063 - val_loss: 0.0709 - val_mean_absolute_error: 0.0542 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.07095 to 0.07087, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 82/250\n",
      " - 8s - loss: 0.0787 - mean_absolute_error: 0.0600 - mean_squared_error: 0.0062 - val_loss: 0.0709 - val_mean_absolute_error: 0.0543 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.07087\n",
      "Epoch 83/250\n",
      " - 8s - loss: 0.0786 - mean_absolute_error: 0.0599 - mean_squared_error: 0.0062 - val_loss: 0.0713 - val_mean_absolute_error: 0.0547 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.07087\n",
      "Epoch 84/250\n",
      " - 8s - loss: 0.0789 - mean_absolute_error: 0.0601 - mean_squared_error: 0.0062 - val_loss: 0.0711 - val_mean_absolute_error: 0.0544 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.07087\n",
      "Epoch 85/250\n",
      " - 8s - loss: 0.0787 - mean_absolute_error: 0.0599 - mean_squared_error: 0.0062 - val_loss: 0.0719 - val_mean_absolute_error: 0.0550 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.07087\n",
      "Epoch 86/250\n",
      " - 8s - loss: 0.0788 - mean_absolute_error: 0.0600 - mean_squared_error: 0.0062 - val_loss: 0.0708 - val_mean_absolute_error: 0.0540 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.07087 to 0.07078, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 87/250\n",
      " - 8s - loss: 0.0787 - mean_absolute_error: 0.0599 - mean_squared_error: 0.0062 - val_loss: 0.0711 - val_mean_absolute_error: 0.0544 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.07078\n",
      "Epoch 88/250\n",
      " - 8s - loss: 0.0787 - mean_absolute_error: 0.0599 - mean_squared_error: 0.0062 - val_loss: 0.0713 - val_mean_absolute_error: 0.0545 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.07078\n",
      "Epoch 89/250\n",
      " - 8s - loss: 0.0787 - mean_absolute_error: 0.0599 - mean_squared_error: 0.0062 - val_loss: 0.0711 - val_mean_absolute_error: 0.0543 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.07078\n",
      "Epoch 90/250\n",
      " - 8s - loss: 0.0786 - mean_absolute_error: 0.0599 - mean_squared_error: 0.0062 - val_loss: 0.0706 - val_mean_absolute_error: 0.0538 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.07078 to 0.07058, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 91/250\n",
      " - 8s - loss: 0.0787 - mean_absolute_error: 0.0598 - mean_squared_error: 0.0062 - val_loss: 0.0711 - val_mean_absolute_error: 0.0542 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.07058\n",
      "Epoch 92/250\n",
      " - 9s - loss: 0.0784 - mean_absolute_error: 0.0597 - mean_squared_error: 0.0061 - val_loss: 0.0719 - val_mean_absolute_error: 0.0551 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.07058\n",
      "Epoch 93/250\n",
      " - 8s - loss: 0.0782 - mean_absolute_error: 0.0596 - mean_squared_error: 0.0061 - val_loss: 0.0705 - val_mean_absolute_error: 0.0539 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.07058 to 0.07055, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 94/250\n",
      " - 9s - loss: 0.0784 - mean_absolute_error: 0.0596 - mean_squared_error: 0.0061 - val_loss: 0.0709 - val_mean_absolute_error: 0.0540 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.07055\n",
      "Epoch 95/250\n",
      " - 9s - loss: 0.0786 - mean_absolute_error: 0.0598 - mean_squared_error: 0.0062 - val_loss: 0.0709 - val_mean_absolute_error: 0.0542 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.07055\n",
      "Epoch 96/250\n",
      " - 8s - loss: 0.0782 - mean_absolute_error: 0.0595 - mean_squared_error: 0.0061 - val_loss: 0.0706 - val_mean_absolute_error: 0.0539 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.07055\n",
      "Epoch 97/250\n",
      " - 8s - loss: 0.0783 - mean_absolute_error: 0.0596 - mean_squared_error: 0.0061 - val_loss: 0.0707 - val_mean_absolute_error: 0.0539 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.07055\n",
      "Epoch 98/250\n",
      " - 8s - loss: 0.0779 - mean_absolute_error: 0.0594 - mean_squared_error: 0.0061 - val_loss: 0.0706 - val_mean_absolute_error: 0.0538 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.07055\n",
      "Epoch 99/250\n",
      " - 9s - loss: 0.0783 - mean_absolute_error: 0.0595 - mean_squared_error: 0.0061 - val_loss: 0.0706 - val_mean_absolute_error: 0.0539 - val_mean_squared_error: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00099: val_loss did not improve from 0.07055\n",
      "Epoch 100/250\n",
      " - 8s - loss: 0.0780 - mean_absolute_error: 0.0595 - mean_squared_error: 0.0061 - val_loss: 0.0709 - val_mean_absolute_error: 0.0543 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.07055\n",
      "Epoch 101/250\n",
      " - 8s - loss: 0.0783 - mean_absolute_error: 0.0596 - mean_squared_error: 0.0061 - val_loss: 0.0706 - val_mean_absolute_error: 0.0538 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.07055\n",
      "Epoch 102/250\n",
      " - 8s - loss: 0.0780 - mean_absolute_error: 0.0594 - mean_squared_error: 0.0061 - val_loss: 0.0706 - val_mean_absolute_error: 0.0539 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.07055\n",
      "Epoch 103/250\n",
      " - 8s - loss: 0.0784 - mean_absolute_error: 0.0596 - mean_squared_error: 0.0062 - val_loss: 0.0712 - val_mean_absolute_error: 0.0543 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.07055\n",
      "Epoch 104/250\n",
      " - 8s - loss: 0.0784 - mean_absolute_error: 0.0596 - mean_squared_error: 0.0061 - val_loss: 0.0706 - val_mean_absolute_error: 0.0540 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.07055\n",
      "Epoch 105/250\n",
      " - 8s - loss: 0.0780 - mean_absolute_error: 0.0594 - mean_squared_error: 0.0061 - val_loss: 0.0709 - val_mean_absolute_error: 0.0542 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.07055\n",
      "Epoch 106/250\n",
      " - 8s - loss: 0.0784 - mean_absolute_error: 0.0595 - mean_squared_error: 0.0061 - val_loss: 0.0708 - val_mean_absolute_error: 0.0540 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.07055\n",
      "Epoch 107/250\n",
      " - 9s - loss: 0.0778 - mean_absolute_error: 0.0593 - mean_squared_error: 0.0061 - val_loss: 0.0706 - val_mean_absolute_error: 0.0539 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.07055\n",
      "Epoch 108/250\n",
      " - 9s - loss: 0.0778 - mean_absolute_error: 0.0592 - mean_squared_error: 0.0061 - val_loss: 0.0709 - val_mean_absolute_error: 0.0540 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.07055\n",
      "Epoch 109/250\n",
      " - 8s - loss: 0.0779 - mean_absolute_error: 0.0593 - mean_squared_error: 0.0061 - val_loss: 0.0707 - val_mean_absolute_error: 0.0540 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.07055\n",
      "Epoch 110/250\n",
      " - 8s - loss: 0.0779 - mean_absolute_error: 0.0594 - mean_squared_error: 0.0061 - val_loss: 0.0711 - val_mean_absolute_error: 0.0544 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.07055\n",
      "Epoch 111/250\n",
      " - 8s - loss: 0.0778 - mean_absolute_error: 0.0593 - mean_squared_error: 0.0060 - val_loss: 0.0704 - val_mean_absolute_error: 0.0537 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.07055 to 0.07039, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 112/250\n",
      " - 8s - loss: 0.0775 - mean_absolute_error: 0.0591 - mean_squared_error: 0.0060 - val_loss: 0.0706 - val_mean_absolute_error: 0.0540 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.07039\n",
      "Epoch 113/250\n",
      " - 8s - loss: 0.0778 - mean_absolute_error: 0.0592 - mean_squared_error: 0.0061 - val_loss: 0.0706 - val_mean_absolute_error: 0.0539 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.07039\n",
      "Epoch 114/250\n",
      " - 8s - loss: 0.0775 - mean_absolute_error: 0.0590 - mean_squared_error: 0.0060 - val_loss: 0.0705 - val_mean_absolute_error: 0.0537 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.07039\n",
      "Epoch 115/250\n",
      " - 8s - loss: 0.0776 - mean_absolute_error: 0.0591 - mean_squared_error: 0.0060 - val_loss: 0.0704 - val_mean_absolute_error: 0.0537 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.07039\n",
      "Epoch 116/250\n",
      " - 8s - loss: 0.0777 - mean_absolute_error: 0.0591 - mean_squared_error: 0.0060 - val_loss: 0.0705 - val_mean_absolute_error: 0.0537 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.07039\n",
      "Epoch 117/250\n",
      " - 9s - loss: 0.0776 - mean_absolute_error: 0.0591 - mean_squared_error: 0.0060 - val_loss: 0.0709 - val_mean_absolute_error: 0.0540 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.07039\n",
      "Epoch 118/250\n",
      " - 9s - loss: 0.0774 - mean_absolute_error: 0.0589 - mean_squared_error: 0.0060 - val_loss: 0.0704 - val_mean_absolute_error: 0.0537 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.07039\n",
      "Epoch 119/250\n",
      " - 9s - loss: 0.0775 - mean_absolute_error: 0.0590 - mean_squared_error: 0.0060 - val_loss: 0.0708 - val_mean_absolute_error: 0.0541 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.07039\n",
      "Epoch 120/250\n",
      " - 9s - loss: 0.0777 - mean_absolute_error: 0.0591 - mean_squared_error: 0.0060 - val_loss: 0.0703 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.07039 to 0.07034, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 121/250\n",
      " - 8s - loss: 0.0774 - mean_absolute_error: 0.0590 - mean_squared_error: 0.0060 - val_loss: 0.0705 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.07034\n",
      "Epoch 122/250\n",
      " - 8s - loss: 0.0772 - mean_absolute_error: 0.0588 - mean_squared_error: 0.0060 - val_loss: 0.0704 - val_mean_absolute_error: 0.0537 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.07034\n",
      "Epoch 123/250\n",
      " - 9s - loss: 0.0774 - mean_absolute_error: 0.0590 - mean_squared_error: 0.0060 - val_loss: 0.0703 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.07034\n",
      "Epoch 124/250\n",
      " - 9s - loss: 0.0775 - mean_absolute_error: 0.0589 - mean_squared_error: 0.0060 - val_loss: 0.0703 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.07034 to 0.07030, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 125/250\n",
      " - 9s - loss: 0.0773 - mean_absolute_error: 0.0589 - mean_squared_error: 0.0060 - val_loss: 0.0704 - val_mean_absolute_error: 0.0538 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.07030\n",
      "Epoch 126/250\n",
      " - 9s - loss: 0.0773 - mean_absolute_error: 0.0589 - mean_squared_error: 0.0060 - val_loss: 0.0704 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.07030\n",
      "Epoch 127/250\n",
      " - 9s - loss: 0.0774 - mean_absolute_error: 0.0589 - mean_squared_error: 0.0060 - val_loss: 0.0704 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.07030\n",
      "Epoch 128/250\n",
      " - 9s - loss: 0.0774 - mean_absolute_error: 0.0590 - mean_squared_error: 0.0060 - val_loss: 0.0705 - val_mean_absolute_error: 0.0538 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.07030\n",
      "Epoch 129/250\n",
      " - 9s - loss: 0.0771 - mean_absolute_error: 0.0587 - mean_squared_error: 0.0059 - val_loss: 0.0702 - val_mean_absolute_error: 0.0535 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.07030 to 0.07021, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 130/250\n",
      " - 9s - loss: 0.0774 - mean_absolute_error: 0.0590 - mean_squared_error: 0.0060 - val_loss: 0.0706 - val_mean_absolute_error: 0.0540 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.07021\n",
      "Epoch 131/250\n",
      " - 9s - loss: 0.0773 - mean_absolute_error: 0.0588 - mean_squared_error: 0.0060 - val_loss: 0.0703 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.07021\n",
      "Epoch 132/250\n",
      " - 9s - loss: 0.0771 - mean_absolute_error: 0.0587 - mean_squared_error: 0.0059 - val_loss: 0.0705 - val_mean_absolute_error: 0.0540 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.07021\n",
      "Epoch 133/250\n",
      " - 9s - loss: 0.0770 - mean_absolute_error: 0.0587 - mean_squared_error: 0.0059 - val_loss: 0.0702 - val_mean_absolute_error: 0.0535 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.07021\n",
      "Epoch 134/250\n",
      " - 9s - loss: 0.0771 - mean_absolute_error: 0.0588 - mean_squared_error: 0.0059 - val_loss: 0.0704 - val_mean_absolute_error: 0.0538 - val_mean_squared_error: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00134: val_loss did not improve from 0.07021\n",
      "Epoch 135/250\n",
      " - 10s - loss: 0.0768 - mean_absolute_error: 0.0585 - mean_squared_error: 0.0059 - val_loss: 0.0702 - val_mean_absolute_error: 0.0535 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.07021 to 0.07016, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 136/250\n",
      " - 9s - loss: 0.0770 - mean_absolute_error: 0.0587 - mean_squared_error: 0.0059 - val_loss: 0.0702 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.07016\n",
      "Epoch 137/250\n",
      " - 8s - loss: 0.0769 - mean_absolute_error: 0.0586 - mean_squared_error: 0.0059 - val_loss: 0.0702 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.07016\n",
      "Epoch 138/250\n",
      " - 8s - loss: 0.0767 - mean_absolute_error: 0.0585 - mean_squared_error: 0.0059 - val_loss: 0.0702 - val_mean_absolute_error: 0.0535 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.07016\n",
      "Epoch 139/250\n",
      " - 8s - loss: 0.0768 - mean_absolute_error: 0.0585 - mean_squared_error: 0.0059 - val_loss: 0.0706 - val_mean_absolute_error: 0.0538 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.07016\n",
      "Epoch 140/250\n",
      " - 8s - loss: 0.0772 - mean_absolute_error: 0.0587 - mean_squared_error: 0.0060 - val_loss: 0.0701 - val_mean_absolute_error: 0.0534 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.07016 to 0.07008, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 141/250\n",
      " - 8s - loss: 0.0769 - mean_absolute_error: 0.0586 - mean_squared_error: 0.0059 - val_loss: 0.0700 - val_mean_absolute_error: 0.0534 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.07008 to 0.07004, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 142/250\n",
      " - 8s - loss: 0.0768 - mean_absolute_error: 0.0585 - mean_squared_error: 0.0059 - val_loss: 0.0702 - val_mean_absolute_error: 0.0534 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.07004\n",
      "Epoch 143/250\n",
      " - 8s - loss: 0.0765 - mean_absolute_error: 0.0583 - mean_squared_error: 0.0058 - val_loss: 0.0702 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.07004\n",
      "Epoch 144/250\n",
      " - 8s - loss: 0.0771 - mean_absolute_error: 0.0587 - mean_squared_error: 0.0059 - val_loss: 0.0701 - val_mean_absolute_error: 0.0535 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.07004\n",
      "Epoch 145/250\n",
      " - 8s - loss: 0.0768 - mean_absolute_error: 0.0585 - mean_squared_error: 0.0059 - val_loss: 0.0704 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.07004\n",
      "Epoch 146/250\n",
      " - 8s - loss: 0.0769 - mean_absolute_error: 0.0585 - mean_squared_error: 0.0059 - val_loss: 0.0702 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.07004\n",
      "Epoch 147/250\n",
      " - 8s - loss: 0.0769 - mean_absolute_error: 0.0586 - mean_squared_error: 0.0059 - val_loss: 0.0702 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.07004\n",
      "Epoch 148/250\n",
      " - 8s - loss: 0.0766 - mean_absolute_error: 0.0584 - mean_squared_error: 0.0059 - val_loss: 0.0699 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.07004 to 0.06994, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 149/250\n",
      " - 8s - loss: 0.0766 - mean_absolute_error: 0.0583 - mean_squared_error: 0.0059 - val_loss: 0.0701 - val_mean_absolute_error: 0.0535 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.06994\n",
      "Epoch 150/250\n",
      " - 8s - loss: 0.0767 - mean_absolute_error: 0.0585 - mean_squared_error: 0.0059 - val_loss: 0.0702 - val_mean_absolute_error: 0.0535 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.06994\n",
      "Epoch 151/250\n",
      " - 8s - loss: 0.0766 - mean_absolute_error: 0.0583 - mean_squared_error: 0.0059 - val_loss: 0.0701 - val_mean_absolute_error: 0.0535 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.06994\n",
      "Epoch 152/250\n",
      " - 8s - loss: 0.0766 - mean_absolute_error: 0.0583 - mean_squared_error: 0.0059 - val_loss: 0.0699 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.06994\n",
      "Epoch 153/250\n",
      " - 8s - loss: 0.0763 - mean_absolute_error: 0.0582 - mean_squared_error: 0.0058 - val_loss: 0.0701 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.06994\n",
      "Epoch 154/250\n",
      " - 8s - loss: 0.0764 - mean_absolute_error: 0.0582 - mean_squared_error: 0.0058 - val_loss: 0.0701 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.06994\n",
      "Epoch 155/250\n",
      " - 8s - loss: 0.0765 - mean_absolute_error: 0.0583 - mean_squared_error: 0.0059 - val_loss: 0.0699 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.06994\n",
      "Epoch 156/250\n",
      " - 8s - loss: 0.0765 - mean_absolute_error: 0.0583 - mean_squared_error: 0.0059 - val_loss: 0.0702 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.06994\n",
      "Epoch 157/250\n",
      " - 8s - loss: 0.0762 - mean_absolute_error: 0.0581 - mean_squared_error: 0.0058 - val_loss: 0.0699 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.06994 to 0.06990, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 158/250\n",
      " - 8s - loss: 0.0763 - mean_absolute_error: 0.0581 - mean_squared_error: 0.0058 - val_loss: 0.0701 - val_mean_absolute_error: 0.0534 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.06990\n",
      "Epoch 159/250\n",
      " - 8s - loss: 0.0766 - mean_absolute_error: 0.0584 - mean_squared_error: 0.0059 - val_loss: 0.0702 - val_mean_absolute_error: 0.0534 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.06990\n",
      "Epoch 160/250\n",
      " - 9s - loss: 0.0765 - mean_absolute_error: 0.0583 - mean_squared_error: 0.0059 - val_loss: 0.0699 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.06990\n",
      "Epoch 161/250\n",
      " - 9s - loss: 0.0763 - mean_absolute_error: 0.0581 - mean_squared_error: 0.0058 - val_loss: 0.0703 - val_mean_absolute_error: 0.0537 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.06990\n",
      "Epoch 162/250\n",
      " - 8s - loss: 0.0761 - mean_absolute_error: 0.0580 - mean_squared_error: 0.0058 - val_loss: 0.0702 - val_mean_absolute_error: 0.0535 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.06990\n",
      "Epoch 163/250\n",
      " - 8s - loss: 0.0761 - mean_absolute_error: 0.0581 - mean_squared_error: 0.0058 - val_loss: 0.0702 - val_mean_absolute_error: 0.0534 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.06990\n",
      "Epoch 164/250\n",
      " - 8s - loss: 0.0763 - mean_absolute_error: 0.0581 - mean_squared_error: 0.0058 - val_loss: 0.0699 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.06990\n",
      "Epoch 165/250\n",
      " - 8s - loss: 0.0762 - mean_absolute_error: 0.0581 - mean_squared_error: 0.0058 - val_loss: 0.0704 - val_mean_absolute_error: 0.0536 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.06990\n",
      "Epoch 166/250\n",
      " - 8s - loss: 0.0764 - mean_absolute_error: 0.0582 - mean_squared_error: 0.0058 - val_loss: 0.0699 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.06990\n",
      "Epoch 167/250\n",
      " - 8s - loss: 0.0760 - mean_absolute_error: 0.0579 - mean_squared_error: 0.0058 - val_loss: 0.0700 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.06990\n",
      "Epoch 168/250\n",
      " - 10s - loss: 0.0760 - mean_absolute_error: 0.0579 - mean_squared_error: 0.0058 - val_loss: 0.0699 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.06990 to 0.06987, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 169/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 9s - loss: 0.0760 - mean_absolute_error: 0.0579 - mean_squared_error: 0.0058 - val_loss: 0.0701 - val_mean_absolute_error: 0.0535 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.06987\n",
      "Epoch 170/250\n",
      " - 8s - loss: 0.0763 - mean_absolute_error: 0.0581 - mean_squared_error: 0.0058 - val_loss: 0.0703 - val_mean_absolute_error: 0.0535 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.06987\n",
      "Epoch 171/250\n",
      " - 8s - loss: 0.0762 - mean_absolute_error: 0.0581 - mean_squared_error: 0.0058 - val_loss: 0.0700 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.06987\n",
      "Epoch 172/250\n",
      " - 8s - loss: 0.0760 - mean_absolute_error: 0.0579 - mean_squared_error: 0.0058 - val_loss: 0.0703 - val_mean_absolute_error: 0.0535 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.06987\n",
      "Epoch 173/250\n",
      " - 8s - loss: 0.0762 - mean_absolute_error: 0.0581 - mean_squared_error: 0.0058 - val_loss: 0.0705 - val_mean_absolute_error: 0.0537 - val_mean_squared_error: 0.0050\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.06987\n",
      "Epoch 174/250\n",
      " - 9s - loss: 0.0759 - mean_absolute_error: 0.0579 - mean_squared_error: 0.0058 - val_loss: 0.0700 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.06987\n",
      "Epoch 175/250\n",
      " - 8s - loss: 0.0760 - mean_absolute_error: 0.0579 - mean_squared_error: 0.0058 - val_loss: 0.0701 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.06987\n",
      "Epoch 176/250\n",
      " - 8s - loss: 0.0757 - mean_absolute_error: 0.0577 - mean_squared_error: 0.0057 - val_loss: 0.0703 - val_mean_absolute_error: 0.0538 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.06987\n",
      "Epoch 177/250\n",
      " - 8s - loss: 0.0759 - mean_absolute_error: 0.0578 - mean_squared_error: 0.0058 - val_loss: 0.0701 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.06987\n",
      "Epoch 178/250\n",
      " - 8s - loss: 0.0758 - mean_absolute_error: 0.0578 - mean_squared_error: 0.0057 - val_loss: 0.0702 - val_mean_absolute_error: 0.0537 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.06987\n",
      "Epoch 179/250\n",
      " - 8s - loss: 0.0758 - mean_absolute_error: 0.0578 - mean_squared_error: 0.0057 - val_loss: 0.0701 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.06987\n",
      "Epoch 180/250\n",
      " - 8s - loss: 0.0758 - mean_absolute_error: 0.0578 - mean_squared_error: 0.0057 - val_loss: 0.0698 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.06987 to 0.06983, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 181/250\n",
      " - 8s - loss: 0.0758 - mean_absolute_error: 0.0578 - mean_squared_error: 0.0057 - val_loss: 0.0699 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.06983\n",
      "Epoch 182/250\n",
      " - 8s - loss: 0.0758 - mean_absolute_error: 0.0578 - mean_squared_error: 0.0057 - val_loss: 0.0701 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.06983\n",
      "Epoch 183/250\n",
      " - 8s - loss: 0.0758 - mean_absolute_error: 0.0577 - mean_squared_error: 0.0057 - val_loss: 0.0699 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.06983\n",
      "Epoch 184/250\n",
      " - 8s - loss: 0.0758 - mean_absolute_error: 0.0577 - mean_squared_error: 0.0057 - val_loss: 0.0699 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.06983\n",
      "Epoch 185/250\n",
      " - 8s - loss: 0.0758 - mean_absolute_error: 0.0577 - mean_squared_error: 0.0057 - val_loss: 0.0698 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.06983 to 0.06982, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 186/250\n",
      " - 8s - loss: 0.0756 - mean_absolute_error: 0.0576 - mean_squared_error: 0.0057 - val_loss: 0.0700 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.06982\n",
      "Epoch 187/250\n",
      " - 8s - loss: 0.0756 - mean_absolute_error: 0.0577 - mean_squared_error: 0.0057 - val_loss: 0.0698 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.06982\n",
      "Epoch 188/250\n",
      " - 8s - loss: 0.0756 - mean_absolute_error: 0.0577 - mean_squared_error: 0.0057 - val_loss: 0.0700 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.06982\n",
      "Epoch 189/250\n",
      " - 8s - loss: 0.0757 - mean_absolute_error: 0.0577 - mean_squared_error: 0.0057 - val_loss: 0.0698 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.06982\n",
      "Epoch 190/250\n",
      " - 8s - loss: 0.0756 - mean_absolute_error: 0.0577 - mean_squared_error: 0.0057 - val_loss: 0.0698 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.06982 to 0.06977, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 191/250\n",
      " - 8s - loss: 0.0756 - mean_absolute_error: 0.0576 - mean_squared_error: 0.0057 - val_loss: 0.0699 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.06977\n",
      "Epoch 192/250\n",
      " - 8s - loss: 0.0756 - mean_absolute_error: 0.0576 - mean_squared_error: 0.0057 - val_loss: 0.0698 - val_mean_absolute_error: 0.0530 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.06977 to 0.06976, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 193/250\n",
      " - 8s - loss: 0.0755 - mean_absolute_error: 0.0576 - mean_squared_error: 0.0057 - val_loss: 0.0699 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.06976\n",
      "Epoch 194/250\n",
      " - 9s - loss: 0.0757 - mean_absolute_error: 0.0577 - mean_squared_error: 0.0057 - val_loss: 0.0701 - val_mean_absolute_error: 0.0534 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.06976\n",
      "Epoch 195/250\n",
      " - 8s - loss: 0.0755 - mean_absolute_error: 0.0575 - mean_squared_error: 0.0057 - val_loss: 0.0699 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.06976\n",
      "Epoch 196/250\n",
      " - 8s - loss: 0.0755 - mean_absolute_error: 0.0575 - mean_squared_error: 0.0057 - val_loss: 0.0702 - val_mean_absolute_error: 0.0534 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.06976\n",
      "Epoch 197/250\n",
      " - 8s - loss: 0.0756 - mean_absolute_error: 0.0577 - mean_squared_error: 0.0057 - val_loss: 0.0700 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.06976\n",
      "Epoch 198/250\n",
      " - 8s - loss: 0.0755 - mean_absolute_error: 0.0575 - mean_squared_error: 0.0057 - val_loss: 0.0699 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.06976\n",
      "Epoch 199/250\n",
      " - 8s - loss: 0.0756 - mean_absolute_error: 0.0576 - mean_squared_error: 0.0057 - val_loss: 0.0699 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.06976\n",
      "Epoch 200/250\n",
      " - 8s - loss: 0.0753 - mean_absolute_error: 0.0574 - mean_squared_error: 0.0057 - val_loss: 0.0699 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.06976\n",
      "Epoch 201/250\n",
      " - 8s - loss: 0.0752 - mean_absolute_error: 0.0574 - mean_squared_error: 0.0057 - val_loss: 0.0697 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.06976 to 0.06969, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 202/250\n",
      " - 8s - loss: 0.0755 - mean_absolute_error: 0.0575 - mean_squared_error: 0.0057 - val_loss: 0.0698 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.06969\n",
      "Epoch 203/250\n",
      " - 8s - loss: 0.0754 - mean_absolute_error: 0.0574 - mean_squared_error: 0.0057 - val_loss: 0.0697 - val_mean_absolute_error: 0.0530 - val_mean_squared_error: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00203: val_loss did not improve from 0.06969\n",
      "Epoch 204/250\n",
      " - 8s - loss: 0.0754 - mean_absolute_error: 0.0574 - mean_squared_error: 0.0057 - val_loss: 0.0697 - val_mean_absolute_error: 0.0530 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.06969 to 0.06968, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 205/250\n",
      " - 8s - loss: 0.0753 - mean_absolute_error: 0.0574 - mean_squared_error: 0.0057 - val_loss: 0.0698 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.06968\n",
      "Epoch 206/250\n",
      " - 8s - loss: 0.0754 - mean_absolute_error: 0.0575 - mean_squared_error: 0.0057 - val_loss: 0.0699 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.06968\n",
      "Epoch 207/250\n",
      " - 8s - loss: 0.0753 - mean_absolute_error: 0.0574 - mean_squared_error: 0.0057 - val_loss: 0.0700 - val_mean_absolute_error: 0.0534 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.06968\n",
      "Epoch 208/250\n",
      " - 8s - loss: 0.0752 - mean_absolute_error: 0.0573 - mean_squared_error: 0.0057 - val_loss: 0.0698 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.06968\n",
      "Epoch 209/250\n",
      " - 8s - loss: 0.0751 - mean_absolute_error: 0.0573 - mean_squared_error: 0.0056 - val_loss: 0.0702 - val_mean_absolute_error: 0.0534 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.06968\n",
      "Epoch 210/250\n",
      " - 8s - loss: 0.0751 - mean_absolute_error: 0.0573 - mean_squared_error: 0.0056 - val_loss: 0.0697 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.06968 to 0.06968, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 211/250\n",
      " - 8s - loss: 0.0751 - mean_absolute_error: 0.0573 - mean_squared_error: 0.0056 - val_loss: 0.0698 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.06968\n",
      "Epoch 212/250\n",
      " - 8s - loss: 0.0749 - mean_absolute_error: 0.0572 - mean_squared_error: 0.0056 - val_loss: 0.0695 - val_mean_absolute_error: 0.0528 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.06968 to 0.06950, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 213/250\n",
      " - 8s - loss: 0.0752 - mean_absolute_error: 0.0573 - mean_squared_error: 0.0057 - val_loss: 0.0696 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.06950\n",
      "Epoch 214/250\n",
      " - 8s - loss: 0.0750 - mean_absolute_error: 0.0572 - mean_squared_error: 0.0056 - val_loss: 0.0696 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.06950\n",
      "Epoch 215/250\n",
      " - 8s - loss: 0.0751 - mean_absolute_error: 0.0572 - mean_squared_error: 0.0056 - val_loss: 0.0701 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.06950\n",
      "Epoch 216/250\n",
      " - 8s - loss: 0.0749 - mean_absolute_error: 0.0572 - mean_squared_error: 0.0056 - val_loss: 0.0698 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.06950\n",
      "Epoch 217/250\n",
      " - 8s - loss: 0.0752 - mean_absolute_error: 0.0573 - mean_squared_error: 0.0057 - val_loss: 0.0698 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.06950\n",
      "Epoch 218/250\n",
      " - 8s - loss: 0.0752 - mean_absolute_error: 0.0573 - mean_squared_error: 0.0057 - val_loss: 0.0696 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.06950\n",
      "Epoch 219/250\n",
      " - 8s - loss: 0.0747 - mean_absolute_error: 0.0571 - mean_squared_error: 0.0056 - val_loss: 0.0698 - val_mean_absolute_error: 0.0530 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.06950\n",
      "Epoch 220/250\n",
      " - 8s - loss: 0.0750 - mean_absolute_error: 0.0572 - mean_squared_error: 0.0056 - val_loss: 0.0697 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.06950\n",
      "Epoch 221/250\n",
      " - 8s - loss: 0.0748 - mean_absolute_error: 0.0570 - mean_squared_error: 0.0056 - val_loss: 0.0697 - val_mean_absolute_error: 0.0530 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.06950\n",
      "Epoch 222/250\n",
      " - 8s - loss: 0.0749 - mean_absolute_error: 0.0571 - mean_squared_error: 0.0056 - val_loss: 0.0699 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.06950\n",
      "Epoch 223/250\n",
      " - 8s - loss: 0.0747 - mean_absolute_error: 0.0570 - mean_squared_error: 0.0056 - val_loss: 0.0696 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.06950\n",
      "Epoch 224/250\n",
      " - 8s - loss: 0.0749 - mean_absolute_error: 0.0571 - mean_squared_error: 0.0056 - val_loss: 0.0698 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.06950\n",
      "Epoch 225/250\n",
      " - 8s - loss: 0.0748 - mean_absolute_error: 0.0570 - mean_squared_error: 0.0056 - val_loss: 0.0698 - val_mean_absolute_error: 0.0530 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.06950\n",
      "Epoch 226/250\n",
      " - 8s - loss: 0.0746 - mean_absolute_error: 0.0569 - mean_squared_error: 0.0056 - val_loss: 0.0696 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.06950\n",
      "Epoch 227/250\n",
      " - 8s - loss: 0.0747 - mean_absolute_error: 0.0570 - mean_squared_error: 0.0056 - val_loss: 0.0700 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.06950\n",
      "Epoch 228/250\n",
      " - 9s - loss: 0.0747 - mean_absolute_error: 0.0571 - mean_squared_error: 0.0056 - val_loss: 0.0697 - val_mean_absolute_error: 0.0530 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.06950\n",
      "Epoch 229/250\n",
      " - 9s - loss: 0.0747 - mean_absolute_error: 0.0570 - mean_squared_error: 0.0056 - val_loss: 0.0696 - val_mean_absolute_error: 0.0528 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.06950\n",
      "Epoch 230/250\n",
      " - 8s - loss: 0.0747 - mean_absolute_error: 0.0570 - mean_squared_error: 0.0056 - val_loss: 0.0699 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.06950\n",
      "Epoch 231/250\n",
      " - 8s - loss: 0.0748 - mean_absolute_error: 0.0571 - mean_squared_error: 0.0056 - val_loss: 0.0697 - val_mean_absolute_error: 0.0530 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.06950\n",
      "Epoch 232/250\n",
      " - 8s - loss: 0.0748 - mean_absolute_error: 0.0570 - mean_squared_error: 0.0056 - val_loss: 0.0695 - val_mean_absolute_error: 0.0528 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.06950 to 0.06949, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 233/250\n",
      " - 8s - loss: 0.0744 - mean_absolute_error: 0.0568 - mean_squared_error: 0.0055 - val_loss: 0.0697 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.06949\n",
      "Epoch 234/250\n",
      " - 8s - loss: 0.0745 - mean_absolute_error: 0.0569 - mean_squared_error: 0.0056 - val_loss: 0.0696 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.06949\n",
      "Epoch 235/250\n",
      " - 8s - loss: 0.0743 - mean_absolute_error: 0.0568 - mean_squared_error: 0.0055 - val_loss: 0.0696 - val_mean_absolute_error: 0.0528 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.06949\n",
      "Epoch 236/250\n",
      " - 8s - loss: 0.0748 - mean_absolute_error: 0.0570 - mean_squared_error: 0.0056 - val_loss: 0.0696 - val_mean_absolute_error: 0.0530 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.06949\n",
      "Epoch 237/250\n",
      " - 8s - loss: 0.0746 - mean_absolute_error: 0.0569 - mean_squared_error: 0.0056 - val_loss: 0.0696 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.06949\n",
      "Epoch 238/250\n",
      " - 9s - loss: 0.0747 - mean_absolute_error: 0.0569 - mean_squared_error: 0.0056 - val_loss: 0.0695 - val_mean_absolute_error: 0.0528 - val_mean_squared_error: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00238: val_loss improved from 0.06949 to 0.06948, saving model to TEDS_XYZ7_Classification.hdf5\n",
      "Epoch 239/250\n",
      " - 8s - loss: 0.0745 - mean_absolute_error: 0.0569 - mean_squared_error: 0.0056 - val_loss: 0.0696 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.06948\n",
      "Epoch 240/250\n",
      " - 8s - loss: 0.0745 - mean_absolute_error: 0.0568 - mean_squared_error: 0.0055 - val_loss: 0.0697 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.06948\n",
      "Epoch 241/250\n",
      " - 9s - loss: 0.0744 - mean_absolute_error: 0.0568 - mean_squared_error: 0.0055 - val_loss: 0.0697 - val_mean_absolute_error: 0.0530 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.06948\n",
      "Epoch 242/250\n",
      " - 8s - loss: 0.0744 - mean_absolute_error: 0.0568 - mean_squared_error: 0.0055 - val_loss: 0.0695 - val_mean_absolute_error: 0.0528 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.06948\n",
      "Epoch 243/250\n",
      " - 9s - loss: 0.0746 - mean_absolute_error: 0.0569 - mean_squared_error: 0.0056 - val_loss: 0.0696 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.06948\n",
      "Epoch 244/250\n",
      " - 9s - loss: 0.0744 - mean_absolute_error: 0.0568 - mean_squared_error: 0.0055 - val_loss: 0.0695 - val_mean_absolute_error: 0.0528 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.06948\n",
      "Epoch 245/250\n",
      " - 9s - loss: 0.0746 - mean_absolute_error: 0.0569 - mean_squared_error: 0.0056 - val_loss: 0.0698 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.06948\n",
      "Epoch 246/250\n",
      " - 9s - loss: 0.0746 - mean_absolute_error: 0.0569 - mean_squared_error: 0.0056 - val_loss: 0.0696 - val_mean_absolute_error: 0.0530 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.06948\n",
      "Epoch 247/250\n",
      " - 9s - loss: 0.0744 - mean_absolute_error: 0.0568 - mean_squared_error: 0.0055 - val_loss: 0.0695 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.06948\n",
      "Epoch 248/250\n",
      " - 8s - loss: 0.0743 - mean_absolute_error: 0.0567 - mean_squared_error: 0.0055 - val_loss: 0.0695 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.06948\n",
      "Epoch 249/250\n",
      " - 8s - loss: 0.0743 - mean_absolute_error: 0.0567 - mean_squared_error: 0.0055 - val_loss: 0.0696 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.06948\n",
      "Epoch 250/250\n",
      " - 10s - loss: 0.0741 - mean_absolute_error: 0.0566 - mean_squared_error: 0.0055 - val_loss: 0.0695 - val_mean_absolute_error: 0.0528 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.06948 to 0.06948, saving model to TEDS_XYZ7_Classification.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf5c51bb90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz7_model.fit([xyz7_x_train,rul_train], xyz7_y_train, epochs=250, batch_size=512, shuffle=True, validation_split=0.3, verbose=2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5838661 , 0.5548849 , 0.5961297 , ..., 0.569064  ,\n",
       "         0.627631  , 0.65402776],\n",
       "        [0.56520945, 0.5337567 , 0.56853396, ..., 0.53899753,\n",
       "         0.5855118 , 0.6065012 ],\n",
       "        [0.5785205 , 0.54647356, 0.586834  , ..., 0.55750877,\n",
       "         0.60265386, 0.6246188 ],\n",
       "        [0.5756649 , 0.5450725 , 0.5851538 , ..., 0.55424714,\n",
       "         0.59887654, 0.6206935 ],\n",
       "        [0.5777748 , 0.54951966, 0.5892423 , ..., 0.55706185,\n",
       "         0.59597737, 0.6175666 ]],\n",
       "\n",
       "       [[0.5703037 , 0.54357857, 0.5810123 , ..., 0.55693924,\n",
       "         0.63664216, 0.66438854],\n",
       "        [0.54990155, 0.5196589 , 0.5524226 , ..., 0.52674896,\n",
       "         0.5992856 , 0.6208492 ],\n",
       "        [0.55769557, 0.5304658 , 0.5644543 , ..., 0.540351  ,\n",
       "         0.62083274, 0.64388525],\n",
       "        [0.55389595, 0.5285437 , 0.562146  , ..., 0.5358039 ,\n",
       "         0.617737  , 0.6413391 ],\n",
       "        [0.552556  , 0.52979547, 0.56223464, ..., 0.53553   ,\n",
       "         0.6162312 , 0.6396193 ]],\n",
       "\n",
       "       [[0.5723115 , 0.54515934, 0.583416  , ..., 0.5584808 ,\n",
       "         0.63474226, 0.6624281 ],\n",
       "        [0.54812515, 0.51877344, 0.55002505, ..., 0.52538437,\n",
       "         0.6001076 , 0.6214201 ],\n",
       "        [0.5580491 , 0.5311481 , 0.56513715, ..., 0.5407832 ,\n",
       "         0.62135285, 0.64467007],\n",
       "        [0.55366653, 0.5282844 , 0.5617925 , ..., 0.5356578 ,\n",
       "         0.6175732 , 0.6411262 ],\n",
       "        [0.5526595 , 0.529997  , 0.5624149 , ..., 0.53570825,\n",
       "         0.6162699 , 0.6396762 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.6642161 , 0.6479946 , 0.67806166, ..., 0.6655561 ,\n",
       "         0.58465195, 0.58926827],\n",
       "        [0.6515611 , 0.640514  , 0.657335  , ..., 0.6499666 ,\n",
       "         0.54993767, 0.54842705],\n",
       "        [0.6434758 , 0.63435084, 0.6511892 , ..., 0.6458357 ,\n",
       "         0.549509  , 0.5514128 ],\n",
       "        [0.6379107 , 0.6292893 , 0.6465333 , ..., 0.63949263,\n",
       "         0.5498077 , 0.552109  ],\n",
       "        [0.63245404, 0.624123  , 0.6426002 , ..., 0.6338308 ,\n",
       "         0.5459165 , 0.54893523]],\n",
       "\n",
       "       [[0.67037   , 0.6539645 , 0.68502575, ..., 0.67144024,\n",
       "         0.5785867 , 0.5823544 ],\n",
       "        [0.6572776 , 0.6463886 , 0.6635734 , ..., 0.6558373 ,\n",
       "         0.54502547, 0.54275674],\n",
       "        [0.6485066 , 0.6393136 , 0.65650177, ..., 0.65098584,\n",
       "         0.54539526, 0.5466865 ],\n",
       "        [0.64248395, 0.6338843 , 0.6517972 , ..., 0.64401674,\n",
       "         0.54450977, 0.5462768 ],\n",
       "        [0.63810986, 0.6298298 , 0.64916706, ..., 0.63953024,\n",
       "         0.5396044 , 0.54177684]],\n",
       "\n",
       "       [[0.6744567 , 0.65823233, 0.68958735, ..., 0.67562866,\n",
       "         0.5742046 , 0.5770096 ],\n",
       "        [0.6615581 , 0.65093243, 0.66823924, ..., 0.6603954 ,\n",
       "         0.5413488 , 0.53846925],\n",
       "        [0.65380484, 0.64458096, 0.66223025, ..., 0.6563032 ,\n",
       "         0.54049146, 0.54119575],\n",
       "        [0.6487044 , 0.64005315, 0.6586584 , ..., 0.65036035,\n",
       "         0.5388937 , 0.53984696],\n",
       "        [0.6451442 , 0.63665867, 0.6570411 , ..., 0.646429  ,\n",
       "         0.53234535, 0.5336446 ]]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz7_model.predict([xyz7_x_test,rul_testo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## LioNets & Interpretable PCA Experiments \n",
    "Having everything setted up, we are now ready to try our methodology. We first initialize LioNets. LioNets requires a predictor (the classifier itself), an encoder (extracted from the predictor), a decoder, as well as some data (for best results the training data, in order to push the neighbourhood generation through known distribution for the network). \n",
    "\n",
    "We also test the intrepretable capabilities of PCA. Using the LioNet from above we generate a neighbourhood around a test instance and then apply per-sensor PCA reducing the sensor readings dimensionality from 50 (timesteps) to 1. Then we fit the transformed data with their predictions to a Rigde Regression model to acquire the weights(importance) of each sensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lionet = LioNet(predictor, decoder, encoder, LSTM_x_train)\n",
    "ipca = iPCA(lionet.give_me_the_neighbourhood, 2000, 'local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we would like to manually evaluate an instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_instance = LSTM_x_train[112].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LioNets weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=0.0001,fit_intercept=True,random_state=0)\n",
    "lionet_weights, real_prediction, local_prediction = lionet.explain_instance(temp_instance,200,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretable PCA weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_sensor_weights, pca_timestep_weights = ipca.find_importance(temp_instance)\n",
    "pca_timestep_weights = pca_timestep_weights.reshape(700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dict = {'LioNets':lionet_weights,'Interpretable PCA':pca_timestep_weights}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data statistics -> (Global Mean & STD per sensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = LSTM_x_train.reshape(-1,14)\n",
    "global_mean, global_std = [],[]\n",
    "for i in range(14):\n",
    "    global_mean.append(temp_train[:,i].mean())\n",
    "    global_std.append(temp_train[:,i].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make modifications to the measurements of a seleced sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify(temp_instance, weights, sens, mod, uni_sldr=0, rd_btn=1, rng_sldr=(1,50)):\n",
    "    \n",
    "    start, end = rng_sldr[0], rng_sldr[1]\n",
    "    \n",
    "    mod_instance = temp_instance.copy()\n",
    "    local_mean = temp_instance[start-1:end,sens].mean()\n",
    "      \n",
    "    # ---MODS---        \n",
    "    if mod == 1: # Uniform\n",
    "        for i in range(start-1, end):\n",
    "            if weights.reshape(50,14)[i,sens] > 0 and rd_btn > 0:\n",
    "                mod_instance[i,sens] = mod_instance[i,sens] + uni_sldr\n",
    "            if weights.reshape(50,14)[i,sens] < 0 and rd_btn < 0:\n",
    "                mod_instance[i,sens] = mod_instance[i,sens] + uni_sldr    \n",
    "    elif mod == 2: # Local MEan\n",
    "        mod_instance[start-1:end, sens] = local_mean    \n",
    "    elif mod == 3: # Global Mean \n",
    "        mod_instance[start-1:end, sens] = global_mean[sens]   \n",
    "    elif mod == 4: # Zeros\n",
    "        mod_instance[start-1:end, sens] = 0.1    \n",
    "    elif mod == 5: # Gaussian Noise\n",
    "        for i in range(start-1, end):\n",
    "            np.random.seed(2000+i)\n",
    "            gaussian_noise = np.random.normal(global_mean[sens], global_std[sens], 1)/10\n",
    "            mod_instance[i,sens] += gaussian_noise[0]\n",
    "        np.clip(mod_instance,0.1,1.1,out=mod_instance)    \n",
    "    elif mod == 6: # Neural Forecaster\n",
    "        prediction = forecaster.predict(np.expand_dims(temp_instance,axis=0))\n",
    "        prediction = prediction.squeeze()\n",
    "        mod_instance = np.append(temp_instance,prediction,axis=0)\n",
    "        mod_instance = mod_instance[5:]\n",
    "    elif mod == 7: # Static Forecaster\n",
    "        for i in range(mod_instance.shape[1]):\n",
    "            dif = mod_instance[-1,i] - mod_instance[-6:-1,i]\n",
    "            temp = np.flip(dif) + mod_instance[-1,i]\n",
    "            #temp = np.array([dif*(e+1) for e,i in enumerate(range(5))]) + mod_instance[-1,i]\n",
    "            mod_instance[:,i] = np.append(mod_instance[5:,i],temp)  \n",
    "            np.clip(mod_instance[:,i],0.1,1.1,out=mod_instance[:,i])\n",
    "    elif mod == 8: # NBeats Forecaster\n",
    "        prediction = nbeats.predict(np.expand_dims(temp_instance,axis=0))\n",
    "        prediction = prediction.squeeze()\n",
    "        mod_instance = np.append(temp_instance,prediction,axis=0)\n",
    "        mod_instance = mod_instance[5:]\n",
    "        \n",
    "    return mod_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moded_instance_statistics(instance, interpret_method):\n",
    "    \n",
    "    #model = Ridge(alpha=0.0001,fit_intercept=True,random_state=0)\n",
    "    #weights, real_prediction, local_prediction = lionet.explain_instance(instance,200,model)\n",
    "    #weights = weights * instance.reshape(700)\n",
    "    if interpret_method == 'Interpretable PCA':\n",
    "        _, weights = ipca.find_importance(instance)\n",
    "        weights = weights.reshape(700)\n",
    "        print(\"It crashes here: moded_instance_statistics in the first if else. You need to define real prediction using your model\\\n",
    "              and you also need to define the local prediction. You need this information through PCA so you should change the code there!!!!\")\n",
    "        #!You should calculate here the realPred and the localPred by InterpretablePCA\n",
    "    else:\n",
    "        model = Ridge(alpha=0.0001,fit_intercept=True,random_state=0)\n",
    "        weights, real_prediction, local_prediction = lionet.explain_instance(instance,200,model)\n",
    "        weights = weights * instance.reshape(700)\n",
    "    sensors_all = {}\n",
    "    count = 0\n",
    "    for j in range(50):\n",
    "        count2 = 0\n",
    "        for i in sensors:\n",
    "            sensors_all.setdefault(i,[]).append([j, weights[count+count2], instance[j][count2],\n",
    "                                                 weights[count+count2]*instance[j][count2]])\n",
    "            count2 = count2 + 1\n",
    "        count = count + 14\n",
    "        \n",
    "    sensors_std = []\n",
    "    sensors_mean = []\n",
    "    sensors_max = []\n",
    "    sensors_min = []\n",
    "    for i in sensors_all:\n",
    "        naa = np.array(sensors_all[i])[:,3]\n",
    "        sensors_std.append(naa.std())\n",
    "        sensors_mean.append(naa.mean())\n",
    "        sensors_max.append(naa.max())\n",
    "        sensors_min.append(naa.min())\n",
    "        \n",
    "    return [real_prediction, local_prediction], sensors_all, [sensors_mean,sensors_std,sensors_min,sensors_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find 2 sensors with the most negative and positive influence based on the mean of time-step feature weights.\n",
    "\n",
    "Then recommend certain modifications that can be applied on their measurements that lead to a change in the RUL propability estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_modifications(instance, weights, interpret_method):\n",
    "    \n",
    "    _, _, original_sens_stats = moded_instance_statistics(instance,interpret_method)\n",
    "    sensors_mean =  original_sens_stats[0]\n",
    "    indexed = list(enumerate(sensors_mean))\n",
    "    indexed.sort(key=lambda tup: tup[1])\n",
    "    cls0_sens = list([i for i, v in indexed[:2]])\n",
    "    cls1_sens = list(reversed([i for i, v in indexed[-2:]]))\n",
    "#     print(\"Class 0 important sensors:\",sensors[cls0_sens[0]], sensors[cls0_sens[1]])\n",
    "#     print(\"Class 1 important sensors:\",sensors[cls1_sens[0]], sensors[cls1_sens[1]])\n",
    "\n",
    "    mods = ['Original', 'Uniform', 'Mean(Local)', 'Mean(Global)', 'Zero', \\\n",
    "            'Noise', 'Forecast (Neural)', 'Forecast (Static)', 'Forecast (N-Beats)']\n",
    "    wghts = ['Negative Weights', 'Positive Weights']\n",
    "    \n",
    "    cls0_mod_results = []\n",
    "    cls1_mod_results = []\n",
    "    unif_tests= [0.1, 0.5, -0.1, -0.5]\n",
    "    \n",
    "    for sens in cls0_sens:\n",
    "        temp = []\n",
    "        for v,w in zip(unif_tests,np.sign(unif_tests)):\n",
    "            mod_inst = modify(instance, weights, sens, 1, v, w)\n",
    "            mod_preds = predictor.predict(np.array([mod_inst,mod_inst]))[0]\n",
    "            temp.append((mod_preds[0],sens,1,v,w))#it was mod_preds[1]\n",
    "        for mod in range(2,len(mods)):\n",
    "            mod_inst = modify(instance, weights, sens, mod)\n",
    "            mod_preds = predictor.predict(np.array([mod_inst,mod_inst]))[0]\n",
    "            temp.append((mod_preds[0],sens,mod))#it was mod_preds[1]\n",
    "        cls0_mod_results.append(max(temp))\n",
    "\n",
    "    for sens in cls1_sens:\n",
    "        temp = []\n",
    "        for v,w in zip(unif_tests,-np.sign(unif_tests)):\n",
    "            mod_inst = modify(instance, weights, sens, 1, v, w)\n",
    "            mod_preds = predictor.predict(np.array([mod_inst,mod_inst]))[0]\n",
    "            temp.append((mod_preds[0],sens,1,v,w))#it was mod_preds[1]\n",
    "        for mod in range(2,len(mods)):\n",
    "            mod_inst = modify(instance, weights, sens, mod)\n",
    "            mod_preds = predictor.predict(np.array([mod_inst,mod_inst]))[0]\n",
    "            temp.append((mod_preds[0],sens,mod))#it was mod_preds[1]\n",
    "        cls1_mod_results.append(min(temp))\n",
    "\n",
    "\n",
    "    recommendation = \"\\t\\t\\t\\t\\t\\t<<< Recommendations >>>\\n\\n\"\n",
    "    for e0,rec in enumerate(cls0_mod_results):\n",
    "        if rec[2]==1:\n",
    "            recommendation += str(e0+1)+\") Try the Uniform modification on sensor \"+str(sensors[rec[1]])+\\\n",
    "            \" with Value: \"+str(rec[3])+\" on the \"+str(wghts[int((1+rec[4])/2)])+\" to increase the RUL propability.\\n\"\n",
    "        else:\n",
    "            recommendation += str(e0+1)+\") Try the \"+str(mods[rec[2]])+\" modification on sensor \"+str(sensors[rec[1]])+ \\\n",
    "            \" to increase the RUL propability.\\n\"\n",
    "       \n",
    "    for e1,rec in enumerate(cls1_mod_results):\n",
    "        if rec[2]==1:\n",
    "            recommendation += str(e1+e0+2)+\") Try the Uniform modification on sensor \"+str(sensors[rec[1]])+\\\n",
    "            \" with Value: \"+str(rec[3])+\" on the \"+str(wghts[int((1+rec[4])/2)])+\" to decrease the RUL propability.\\n\"\n",
    "        else:\n",
    "            recommendation += str(e1+e0+2)+\") Try the \"+str(mods[rec[2]])+\" modification on sensor \"+str(sensors[rec[1]])+ \\\n",
    "            \" to decrease the RUL propability.\\n\"\n",
    "            \n",
    "    return recommendation\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the new modified instances and inspect the changes of the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Original stats\n",
    "original_preds, original_sens_all, original_sens_stats = {},{},{}\n",
    "for method in weights_dict.keys():\n",
    "    original_preds[method], original_sens_all[method], original_sens_stats[method] = \\\n",
    "    moded_instance_statistics(temp_instance,method)\n",
    "\n",
    "# Recommend modifications\n",
    "recommendation = {}\n",
    "for method in weights_dict.keys():\n",
    "    recommendation[method] = recommend_modifications(temp_instance, weights_dict[method], method)  # Lionets & IPCA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98f15ef009940b8a896c3ff3d674997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Interpretation method:'), ToggleButtons(options=('LioNets', 'Interp"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf316f698f94544be621a594f7af921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seeSens =  1\n",
    "def plot_sensor(sens_i, mod_sens_i, mod, rng_sldr, uni_sldr, rd_btn, interpret_method):\n",
    "    \n",
    "    global seeSens, mod_preds, mod_sens_all, mod_sens_stats\n",
    "    \n",
    "    # Recommend modifications\n",
    "    print(recommendation[interpret_method])\n",
    "    \n",
    "    # Disable/Enable UI elements\n",
    "    uniform_slider.disabled, radio_button.disabled = True, True\n",
    "    modify_sens_i.disabled, range_slider.disabled =  False, False\n",
    "    if mod==1:\n",
    "        uniform_slider.disabled, radio_button.disabled = False, False\n",
    "    if mod==0 or mod==6 or mod==7 or mod==8:\n",
    "        modify_sens_i.disabled, range_slider.disabled = True, True\n",
    "    \n",
    "    # If a UI element has been changed other than the Sensor View proceed to the modification\n",
    "    if seeSens == sens_i:\n",
    "        inst_mod = modify(temp_instance, weights_dict[interpret_method], mod_sens_i-1, mod, uni_sldr, rd_btn, rng_sldr)\n",
    "        mod_preds, mod_sens_all, mod_sens_stats = moded_instance_statistics(inst_mod, interpret_method)\n",
    "    else:\n",
    "        seeSens = sens_i\n",
    "        \n",
    "    # Print the predictions of RUL for the original and modified instance \n",
    "    print(\"ORIGINAL -> Real prediction: \" + str(original_preds[interpret_method][0])[:7] + \\\n",
    "                   \", Local prediction: \" + str(original_preds[interpret_method][1])[:7])\n",
    "    print(\"  MOD    -> Real prediction: \" + str(mod_preds[0])[:7] + \", Local prediction: \" + str(mod_preds[1])[:7])\n",
    "    \n",
    "    # Plotting the figures \n",
    "    to_vis = [i[2:] for i in sensors]\n",
    "    x = np.arange(len(to_vis))\n",
    "    width = 0.4\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 4), dpi=200)\n",
    "    axs[0].bar(x-width, original_sens_stats[interpret_method][0], width=width, tick_label=to_vis, align='edge', color='C0')\n",
    "    axs[0].bar(x, mod_sens_stats[0], width=width, tick_label=to_vis, align='edge', color='C1')\n",
    "    axs[0].set_title('Mean')\n",
    "    axs[0].legend(('riginal','Modded'))\n",
    "    axs[1].bar(x-width, original_sens_stats[interpret_method][1], width=width, tick_label=to_vis, align='edge', color='C0')\n",
    "    axs[1].bar(x, mod_sens_stats[1], width=width, tick_label=to_vis, align='edge', color='C1')\n",
    "    axs[1].set_title('STD')\n",
    "    axs[2].bar(x-width, original_sens_stats[interpret_method][2], width=width, tick_label=to_vis, align='edge', color='C0',)\n",
    "    axs[2].bar(x-width, original_sens_stats[interpret_method][3], width=width, tick_label=to_vis, align='edge', color='C0')\n",
    "    axs[2].bar(x, mod_sens_stats[2], width=width, tick_label=to_vis, align='edge', color='C1')\n",
    "    axs[2].bar(x, mod_sens_stats[3], width=width, tick_label=to_vis, align='edge', color='C1')\n",
    "    axs[2].set_title('Max and Min')  \n",
    "    #for i in rec_sens:\n",
    "    #    org_means[i].set_ecolor('r')\n",
    "    \n",
    "    #fig.suptitle('Sensor Importance Statistics')\n",
    "    plt.show()\n",
    "\n",
    "    TIMESTEPS = np.arange(temp_instance.shape[0])\n",
    "    \n",
    "    plt.figure(figsize=(14, 4), dpi=200, facecolor='w', edgecolor='k')\n",
    "    plt.subplot(131)\n",
    "    plt.plot(TIMESTEPS,np.array(original_sens_all[interpret_method][sensors[sens_i-1]])[:,1],color='grey',linestyle = ':')\n",
    "    plt.plot(TIMESTEPS,np.array(mod_sens_all[sensors[sens_i-1]])[:,1],color='tab:blue')\n",
    "    plt.hlines(y=np.array(mod_sens_all[sensors[sens_i-1]])[:,1].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" influence\"))\n",
    "    plt.subplot(132)\n",
    "    plt.plot(TIMESTEPS,np.array(original_sens_all[interpret_method][sensors[sens_i-1]])[:,2],color='grey',linestyle = ':')\n",
    "    if inst_mod is not None: #I fixed this I think. \n",
    "        plt.plot(TIMESTEPS,inst_mod[:,sens_i-1:sens_i],color='g')\n",
    "    plt.hlines(y=np.array(mod_sens_all[sensors[sens_i-1]])[:,2].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" value\"))\n",
    "    plt.subplot(133)\n",
    "    plt.plot(TIMESTEPS,np.array(original_sens_all[interpret_method][sensors[sens_i-1]])[:,3],color='grey',linestyle = ':')\n",
    "    plt.plot(TIMESTEPS,np.array(mod_sens_all[sensors[sens_i-1]])[:,3],color='r')\n",
    "    plt.hlines(y=np.array(mod_sens_all[sensors[sens_i-1]])[:,3].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" influence * value\"))\n",
    "    plt.show()\n",
    "    \n",
    "                            ### Setting up the interactive visualization tool ###\n",
    "\n",
    "# UI elements\n",
    "range_slider = IntRangeSlider(value=[1,50], min=1, max=50, description=\"Range: \", continuous_update = False)\n",
    "view_sens_i = IntSlider(min=1, max=14, default_value=2, description=\"View Sensor: \", continuous_update = False)\n",
    "modify_sens_i = IntSlider(min=1, max=14, default_value=2, description=\"Mod Sensor: \", continuous_update = False)\n",
    "uniform_slider = FloatSlider(value=0, min=-1.1, max=1.1, step=0.05, description='Value:', continuous_update = False)\n",
    "radio_button = RadioButtons(options=[('Positive Weights', 1), ('Negative Weights', -1)], description='Affect:')\n",
    "interpret_method = ToggleButtons(options=['LioNets', 'Interpretable PCA'])\n",
    "mod = Dropdown(options=[('Original', 0), ('Uniform', 1), ('Mean (Local)', 2), ('Mean (Global)', 3), ('Zero', 4), ('Noise', 5),\n",
    "                        ('Forecast (Neural)', 6), ('Forecast (Static)', 7), ('Forecast (N-Beats)', 8)], description=\"Mods: \")\n",
    "jsdlink((modify_sens_i, 'value'), (view_sens_i, 'value'))\n",
    "\n",
    "# UI layout\n",
    "interpretable_settings = HBox([Label('Interpretation method:'), interpret_method])\n",
    "interpretable_settings.layout.margin = '0 0 20px 0'\n",
    "mod_settings = HBox([VBox([modify_sens_i,view_sens_i]), VBox([mod, range_slider]), VBox([uniform_slider, radio_button])])\n",
    "ui = VBox([interpretable_settings, mod_settings])\n",
    "\n",
    "# Starting the interactive tool\n",
    "inter = interactive_output(plot_sensor, {'sens_i':view_sens_i, 'mod_sens_i':modify_sens_i, \n",
    "                                         'mod':mod, 'rng_sldr':range_slider, 'uni_sldr':uniform_slider, \n",
    "                                         'rd_btn':radio_button, 'interpret_method': interpret_method})\n",
    "display(ui,inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
